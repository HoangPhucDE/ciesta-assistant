#!/usr/bin/env python3
"""
Script ƒë·ªÉ fix entity alignment trong training data s·ª≠ d·ª•ng Rasa's tokenizer
ƒêi·ªÅu ch·ªânh entity annotations ƒë·ªÉ kh·ªõp v·ªõi token boundaries

C√°ch s·ª≠ d·ª•ng:
    python scripts/training/fix_entity_alignments_rasa.py data/nlu.yml

Ho·∫∑c tr√™n Colab:
    !python scripts/training/fix_entity_alignments_rasa.py data/nlu.yml
"""

import sys
import re
from pathlib import Path
from typing import List, Tuple, Optional

# Try to import Rasa components
try:
    from rasa.nlu.tokenizers.whitespace_tokenizer import WhitespaceTokenizer
    from rasa.shared.nlu.training_data.formats.rasa_yaml import RasaYAMLReader
    from rasa.shared.nlu.training_data.training_data import TrainingData
    RASA_AVAILABLE = True
except ImportError:
    RASA_AVAILABLE = False
    print("‚ö†Ô∏è Rasa kh√¥ng ƒë∆∞·ª£c c√†i ƒë·∫∑t, s·∫Ω s·ª≠ d·ª•ng tokenizer ƒë∆°n gi·∫£n")


def simple_tokenize(text: str) -> List[Tuple[int, int, str]]:
    """
    Simple whitespace tokenizer (fallback n·∫øu kh√¥ng c√≥ Rasa)
    """
    tokens = []
    words = text.split()
    current_pos = 0
    
    for word in words:
        start = text.find(word, current_pos)
        if start == -1:
            start = current_pos
            while start < len(text) and text[start].isspace():
                start += 1
            if start >= len(text):
                break
        end = start + len(word)
        tokens.append((start, end, word))
        current_pos = end
    
    return tokens


def fix_entity_alignment_rasa(text: str, entity_value: str, entity_type: str) -> Optional[str]:
    """
    Fix entity alignment s·ª≠ d·ª•ng Rasa tokenizer n·∫øu c√≥
    """
    if not RASA_AVAILABLE:
        # Fallback: s·ª≠ d·ª•ng simple tokenizer
        tokens = simple_tokenize(text)
        
        # T√¨m entity value trong text
        entity_words = entity_value.split()
        token_texts = [t[2] for t in tokens]
        
        # T√¨m sequence kh·ªõp
        for i in range(len(token_texts) - len(entity_words) + 1):
            match = True
            for j, ew in enumerate(entity_words):
                if i + j >= len(token_texts):
                    match = False
                    break
                if token_texts[i + j].lower() != ew.lower():
                    match = False
                    break
            
            if match:
                start_token = tokens[i]
                end_token = tokens[i + len(entity_words) - 1]
                aligned_value = text[start_token[0]:end_token[1]]
                if aligned_value != entity_value:
                    return aligned_value
        
        return None
    
    # S·ª≠ d·ª•ng Rasa tokenizer
    tokenizer = WhitespaceTokenizer()
    message_data = {"text": text}
    
    # Tokenize
    tokens = tokenizer.tokenize(message_data, attribute="text")
    
    # T√¨m tokens kh·ªõp v·ªõi entity
    entity_words = entity_value.split()
    token_texts = [t.text for t in tokens]
    
    # T√¨m sequence
    for i in range(len(token_texts) - len(entity_words) + 1):
        match = True
        for j, ew in enumerate(entity_words):
            if i + j >= len(token_texts):
                match = False
                break
            if token_texts[i + j].lower() != ew.lower():
                match = False
                break
        
        if match:
            start_token = tokens[i]
            end_token = tokens[i + len(entity_words) - 1]
            aligned_value = text[start_token.start:end_token.end]
            if aligned_value != entity_value:
                return aligned_value
    
    return None


def fix_example_line(line: str) -> str:
    """
    Fix m·ªôt d√≤ng example
    """
    # Parse entity pattern: [value](type)
    entity_pattern = r'\[([^\]]+)\]\(([^)]+)\)'
    entities = re.findall(entity_pattern, line)
    
    if not entities:
        return line
    
    # L·∫•y text g·ªëc (thay [entity](type) b·∫±ng entity value)
    text_only = re.sub(entity_pattern, r'\1', line)
    
    fixed_line = line
    
    # Fix t·ª´ng entity
    for entity_value, entity_type in entities:
        # T√¨m alignment t·ªët h∆°n
        aligned_value = fix_entity_alignment_rasa(text_only, entity_value, entity_type)
        
        if aligned_value and aligned_value != entity_value:
            # Thay th·∫ø annotation
            old_annotation = f'[{entity_value}]({entity_type})'
            new_annotation = f'[{aligned_value}]({entity_type})'
            fixed_line = fixed_line.replace(old_annotation, new_annotation, 1)
    
    return fixed_line


def fix_nlu_file_rasa(input_file: Path, output_file: Path = None):
    """
    Fix entity alignments s·ª≠ d·ª•ng Rasa n·∫øu c√≥ th·ªÉ
    """
    if output_file is None:
        output_file = input_file
    
    print(f"üìñ ƒê·ªçc file: {input_file}")
    
    if RASA_AVAILABLE:
        # S·ª≠ d·ª•ng Rasa's training data reader
        try:
            reader = RasaYAMLReader()
            training_data = reader.read(input_file)
            
            print(f"üîç ƒêang x·ª≠ l√Ω {len(training_data.training_examples)} examples...")
            
            # Fix t·ª´ng example
            fixed_count = 0
            for example in training_data.training_examples:
                original_text = example.get("text")
                entities = example.get("entities", [])
                
                if not entities:
                    continue
                
                # Tokenize v·ªõi WhitespaceTokenizer
                tokenizer = WhitespaceTokenizer()
                message_data = {"text": original_text}
                tokens = tokenizer.tokenize(message_data, attribute="text")
                
                # Fix t·ª´ng entity
                fixed_entities = []
                for entity in entities:
                    entity_start = entity["start"]
                    entity_end = entity["end"]
                    entity_value = entity["value"]
                    
                    # T√¨m tokens n·∫±m trong entity
                    entity_tokens = [
                        t for t in tokens
                        if t.start < entity_end and t.end > entity_start
                    ]
                    
                    if entity_tokens:
                        # Align v·ªõi token boundaries
                        aligned_start = min(t.start for t in entity_tokens)
                        aligned_end = max(t.end for t in entity_tokens)
                        aligned_value = original_text[aligned_start:aligned_end]
                        
                        if aligned_value != entity_value:
                            entity["start"] = aligned_start
                            entity["end"] = aligned_end
                            entity["value"] = aligned_value
                            fixed_count += 1
                    
                    fixed_entities.append(entity)
                
                example.set("entities", fixed_entities)
            
            print(f"‚úÖ ƒê√£ fix {fixed_count} entities")
            
            # Save l·∫°i file
            # Note: Rasa kh√¥ng c√≥ writer tr·ª±c ti·∫øp cho YAML, n√™n s·∫Ω d√πng c√°ch kh√°c
            print("üíæ ƒêang ghi file...")
            # T·∫°m th·ªùi s·∫Ω d√πng c√°ch ƒë·ªçc v√† s·ª≠a file YAML tr·ª±c ti·∫øp
            
        except Exception as e:
            print(f"‚ùå L·ªói khi s·ª≠ d·ª•ng Rasa: {e}")
            print("   S·ª≠ d·ª•ng ph∆∞∆°ng ph√°p ƒë∆°n gi·∫£n h∆°n...")
            RASA_AVAILABLE = False
    
    if not RASA_AVAILABLE:
        # Ph∆∞∆°ng ph√°p ƒë∆°n gi·∫£n: ƒë·ªçc file YAML v√† s·ª≠a t·ª´ng d√≤ng
        with open(input_file, 'r', encoding='utf-8') as f:
            lines = f.readlines()
        
        fixed_lines = []
        fixed_count = 0
        
        for line in lines:
            original_line = line
            # Ch·ªâ fix c√°c d√≤ng c√≥ entity annotations
            if '[' in line and '](' in line:
                fixed_line = fix_example_line(line.rstrip('\n'))
                if fixed_line != line.rstrip('\n'):
                    fixed_count += 1
                fixed_lines.append(fixed_line + '\n')
            else:
                fixed_lines.append(line)
        
        print(f"‚úÖ ƒê√£ fix {fixed_count} examples")
        
        # Backup file g·ªëc
        backup_file = input_file.with_suffix('.yml.bak')
        print(f"üíæ Backup file g·ªëc: {backup_file}")
        with open(backup_file, 'w', encoding='utf-8') as f:
            f.writelines(lines)
        
        # Ghi file m·ªõi
        print(f"üíæ Ghi file m·ªõi: {output_file}")
        with open(output_file, 'w', encoding='utf-8') as f:
            f.writelines(fixed_lines)
    
    print("‚úÖ Ho√†n t·∫•t!")


def main():
    """Main function"""
    import argparse
    
    parser = argparse.ArgumentParser(description='Fix entity alignments in NLU training data')
    parser.add_argument('input_file', type=str, help='Input NLU YAML file')
    parser.add_argument('-o', '--output', type=str, default=None, help='Output file')
    
    args = parser.parse_args()
    
    input_path = Path(args.input_file)
    if not input_path.exists():
        print(f"‚ùå File kh√¥ng t·ªìn t·∫°i: {input_path}")
        sys.exit(1)
    
    output_path = Path(args.output) if args.output else input_path
    
    fix_nlu_file_rasa(input_path, output_path)


if __name__ == '__main__':
    main()

