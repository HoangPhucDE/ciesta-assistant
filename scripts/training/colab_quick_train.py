#!/usr/bin/env python3
"""
Script ƒë∆°n gi·∫£n ƒë·ªÉ train Rasa NLU tr√™n Google Colab
Copy-paste to√†n b·ªô script n√†y v√†o m·ªôt cell trong Colab v√† ch·∫°y
"""

# ============================================================================
# CONFIGURATION - Ch·ªânh s·ª≠a ph·∫ßn n√†y n·∫øu c·∫ßn
# ============================================================================
USE_GPU = True  # Set True ƒë·ªÉ s·ª≠ d·ª•ng GPU (khuy·∫øn ngh·ªã)
REDUCE_MEMORY = False  # Set True n·∫øu g·∫∑p l·ªói Out of Memory
EPOCHS = None  # None = d√πng epochs t·ª´ config.yml, ho·∫∑c set s·ªë c·ª• th·ªÉ (v√≠ d·ª•: 300)

# ============================================================================
# MAIN SCRIPT - Kh√¥ng c·∫ßn ch·ªânh s·ª≠a ph·∫ßn d∆∞·ªõi
# ============================================================================

import os
import sys
import subprocess
import shutil
from pathlib import Path

def print_step(step_num, message):
    """Print step message"""
    print(f"\n{'='*60}")
    print(f"B∆Ø·ªöC {step_num}: {message}")
    print(f"{'='*60}\n")

def check_colab():
    """Check if running on Colab"""
    try:
        import google.colab
        return True
    except ImportError:
        return False

def check_gpu():
    """Check GPU availability"""
    try:
        import torch
        return torch.cuda.is_available()
    except:
        return False

# ============================================================================
# STEP 1: Install Dependencies
# ============================================================================
print_step(1, "C√ÄI ƒê·∫∂T DEPENDENCIES")

# Install system packages
if check_colab():
    print("ƒêang c√†i ƒë·∫∑t system packages...")
    subprocess.run(["apt-get", "install", "-qq", "-y", "git"], check=True)

# Install Python packages
print("ƒêang c√†i ƒë·∫∑t Python packages...")
subprocess.run([
    sys.executable, "-m", "pip", "install", "-q",
    "--upgrade", "pip", "setuptools", "wheel"
], check=True)

if Path("requirements.txt").exists():
    subprocess.run([
        sys.executable, "-m", "pip", "install", "-q",
        "-r", "requirements.txt"
    ], check=True)
    print("‚úÖ ƒê√£ c√†i ƒë·∫∑t dependencies")
else:
    print("‚ö† Kh√¥ng t√¨m th·∫•y requirements.txt")

# ============================================================================
# STEP 2: Check GPU
# ============================================================================
print_step(2, "KI·ªÇM TRA GPU")

if USE_GPU and check_gpu():
    print("‚úÖ GPU ƒë√£ s·∫µn s√†ng - Training s·∫Ω nhanh h∆°n")
elif USE_GPU:
    print("‚ö† GPU kh√¥ng kh·∫£ d·ª•ng - S·ª≠ d·ª•ng CPU")
    print("üí° Tip: V√†o Runtime ‚Üí Change runtime type ‚Üí GPU")
else:
    print("‚Ñπ ƒêang s·ª≠ d·ª•ng CPU")

# ============================================================================
# STEP 3: Setup Directories
# ============================================================================
print_step(3, "THI·∫æT L·∫¨P TH·ª® M·ª§C")

dirs = ["models", "models_hub/phobert-large", "custom_components"]
for d in dirs:
    Path(d).mkdir(parents=True, exist_ok=True)

print("‚úÖ ƒê√£ t·∫°o c√°c th∆∞ m·ª•c c·∫ßn thi·∫øt")

# ============================================================================
# STEP 4: Download PhoBERT Model
# ============================================================================
print_step(4, "T·∫¢I PHOBERT-LARGE MODEL")

model_path = Path("models_hub/phobert-large/config.json")
if model_path.exists():
    print("‚úÖ Model ƒë√£ t·ªìn t·∫°i")
else:
    print("ƒêang t·∫£i model t·ª´ HuggingFace...")
    print("‚è≥ Qu√° tr√¨nh n√†y c√≥ th·ªÉ m·∫•t 5-10 ph√∫t...")
    
    try:
        from huggingface_hub import snapshot_download
        snapshot_download(
            repo_id="vinai/phobert-large",
            local_dir="models_hub/phobert-large",
            local_dir_use_symlinks=False,
            resume_download=True
        )
        print("‚úÖ ƒê√£ t·∫£i model th√†nh c√¥ng")
    except Exception as e:
        print(f"‚ùå L·ªói khi t·∫£i model: {e}")
        sys.exit(1)

# ============================================================================
# STEP 5: Setup Model Path
# ============================================================================
print_step(5, "THI·∫æT L·∫¨P ƒê∆Ø·ªúNG D·∫™N MODEL")

target = Path("models/phobert-large")
if target.exists():
    if target.is_symlink():
        target.unlink()
    else:
        shutil.rmtree(target)

try:
    target.symlink_to(Path("../models_hub/phobert-large").relative_to(target.parent))
    print("‚úÖ ƒê√£ t·∫°o symlink")
except:
    shutil.copytree("models_hub/phobert-large", "models/phobert-large")
    print("‚úÖ ƒê√£ copy model")

# ============================================================================
# STEP 6: Verify Files
# ============================================================================
print_step(6, "KI·ªÇM TRA FILES")

required_files = {
    "config.yml": Path("config.yml"),
    "data/nlu.yml": Path("data/nlu.yml"),
    "custom_components/phobert_featurizer.py": Path("custom_components/phobert_featurizer.py"),
}

missing_files = []
for name, path in required_files.items():
    if path.exists():
        print(f"‚úÖ {name}")
    else:
        print(f"‚ùå {name} - KH√îNG T√åM TH·∫§Y")
        missing_files.append(name)

if missing_files:
    print(f"\n‚ö† Thi·∫øu c√°c file sau: {', '.join(missing_files)}")
    print("Vui l√≤ng upload c√°c file n√†y v√†o Colab tr∆∞·ªõc khi ti·∫øp t·ª•c")
    sys.exit(1)

# ============================================================================
# STEP 7: Adjust Config (if needed)
# ============================================================================
if REDUCE_MEMORY:
    print_step(7, "ƒêI·ªÄU CH·ªàNH CONFIG (Gi·∫£m Memory)")
    
    config_file = Path("config.yml")
    if config_file.exists():
        with open(config_file, "r", encoding="utf-8") as f:
            content = f.read()
        
        # Reduce batch size
        content = content.replace("batch_size: [16, 32]", "batch_size: [8, 16]")
        content = content.replace("batch_size: [32, 64]", "batch_size: [8, 16]")
        
        # Reduce epochs if needed
        if EPOCHS:
            import re
            content = re.sub(r"epochs:\s*\d+", f"epochs: {EPOCHS}", content)
        
        with open(config_file, "w", encoding="utf-8") as f:
            f.write(content)
        
        print("‚úÖ ƒê√£ ƒëi·ªÅu ch·ªânh config ƒë·ªÉ gi·∫£m memory usage")

# ============================================================================
# STEP 8: Train NLU Model
# ============================================================================
print_step(8, "B·∫ÆT ƒê·∫¶U TRAIN NLU MODEL")

print("‚è≥ Training s·∫Ω b·∫Øt ƒë·∫ßu...")
print("üí° Th·ªùi gian ∆∞·ªõc t√≠nh:")
if check_gpu():
    print("   - GPU: 20-40 ph√∫t (600 epochs)")
else:
    print("   - CPU: 1-2 gi·ªù (600 epochs)")

print("\n" + "="*60)
print("B·∫ÆT ƒê·∫¶U TRAINING...")
print("="*60 + "\n")

try:
    import time
    start_time = time.time()
    
    # Train NLU
    result = subprocess.run(
        [sys.executable, "-m", "rasa", "train", "nlu"],
        check=True
    )
    
    elapsed = time.time() - start_time
    hours = int(elapsed // 3600)
    minutes = int((elapsed % 3600) // 60)
    
    print("\n" + "="*60)
    print(f"‚úÖ TRAINING HO√ÄN T·∫§T! Th·ªùi gian: {hours}h {minutes}m")
    print("="*60 + "\n")
    
except subprocess.CalledProcessError as e:
    print(f"\n‚ùå L·ªói khi train: {e}")
    sys.exit(1)
except KeyboardInterrupt:
    print("\n‚ö† Training b·ªã d·ª´ng b·ªüi ng∆∞·ªùi d√πng")
    sys.exit(1)

# ============================================================================
# STEP 9: Get Latest Model
# ============================================================================
print_step(9, "T√åM MODEL ƒê√É TRAIN")

models_dir = Path("models")
model_files = list(models_dir.glob("*.tar.gz"))

if not model_files:
    print("‚ùå Kh√¥ng t√¨m th·∫•y model ƒë√£ train")
    sys.exit(1)

latest_model = max(model_files, key=lambda x: x.stat().st_mtime)
size_mb = latest_model.stat().st_size / (1024 * 1024)

print(f"‚úÖ Model m·ªõi nh·∫•t: {latest_model.name}")
print(f"üì¶ K√≠ch th∆∞·ªõc: {size_mb:.2f} MB")
print(f"üìÅ ƒê∆∞·ªùng d·∫´n: {latest_model}")

# ============================================================================
# STEP 10: Download Model (Colab only)
# ============================================================================
if check_colab():
    print_step(10, "T·∫¢I MODEL V·ªÄ M√ÅY LOCAL")
    
    try:
        from google.colab import files
        files.download(str(latest_model))
        print("‚úÖ ƒê√£ b·∫Øt ƒë·∫ßu t·∫£i model v·ªÅ m√°y local")
    except Exception as e:
        print(f"‚ö† Kh√¥ng th·ªÉ t·∫£i t·ª± ƒë·ªông: {e}")
        print(f"üí° B·∫°n c√≥ th·ªÉ t·∫£i th·ªß c√¥ng t·ª´: {latest_model}")
else:
    print_step(10, "HO√ÄN T·∫§T")
    print(f"‚úÖ Model ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i: {latest_model}")

print("\n" + "="*60)
print("üéâ HO√ÄN T·∫§T T·∫§T C·∫¢ C√ÅC B∆Ø·ªöC!")
print("="*60)
print(f"\nüì¶ Model: {latest_model.name}")
print(f"üìä K√≠ch th∆∞·ªõc: {size_mb:.2f} MB")
print(f"üìÅ V·ªã tr√≠: {latest_model}\n")


