# ============================================
# SETUP VÃ€ TRAIN - COLAB
# ============================================

import os
import shutil
import re
from pathlib import Path

# BÆ°á»›c 1: Cleanup vÃ  Clone
print("ğŸ§¹ Dá»n dáº¹p thÆ° má»¥c cÅ©...")
# XÃ³a táº¥t cáº£ nested directories
base_path = Path("/content")
for path in base_path.glob("ciesta-assistant*"):
    if path.is_dir():
        shutil.rmtree(path, ignore_errors=True)
        print(f"   âœ… ÄÃ£ xÃ³a {path}")

# Äáº£m báº£o Ä‘ang á»Ÿ /content
os.chdir("/content")
print(f"   ThÆ° má»¥c hiá»‡n táº¡i: {os.getcwd()}")

!git clone https://github.com/HoangPhucDE/ciesta-assistant.git
%cd ciesta-assistant
current_dir = Path.cwd()
print(f"âœ… ThÆ° má»¥c: {current_dir}")

# Äáº£m báº£o Ä‘ang á»Ÿ Ä‘Ãºng thÆ° má»¥c root (khÃ´ng pháº£i nested)
while (current_dir / "ciesta-assistant").exists() and current_dir.name == "ciesta-assistant":
    parent = current_dir.parent
    if (parent / "ciesta-assistant").exists() and parent.name != "ciesta-assistant":
        # Äang á»Ÿ trong nested directory, cáº§n lÃªn 1 level
        %cd ..
        current_dir = Path.cwd()
        print(f"   âš ï¸ PhÃ¡t hiá»‡n nested directory, Ä‘Ã£ chuyá»ƒn lÃªn: {current_dir}")
    else:
        break

# BÆ°á»›c 2: CÃ i Ä‘áº·t Python 3.10 (QUAN TRá»ŒNG!)
print("\nğŸ CÃ i Ä‘áº·t Python 3.10...")
!apt-get update -qq
!apt-get install -y -qq python3.10 python3.10-venv python3.10-dev

# BÆ°á»›c 3: Táº¡o virtual environment
print("\nğŸ“¦ Táº¡o virtual environment...")
!python3.10 -m venv venv_py310

# BÆ°á»›c 4: CÃ i Ä‘áº·t dependencies
print("\nğŸ“¦ CÃ i Ä‘áº·t dependencies...")
print("âš ï¸ QUAN TRá»ŒNG: QuÃ¡ trÃ¬nh nÃ y cÃ³ thá»ƒ máº¥t 10-20 phÃºt, KHÃ”NG interrupt!")
print("   Äá»ƒ cÃ i Ä‘áº·t cháº¡y Ä‘áº¿n khi hoÃ n táº¥t...")

# Upgrade pip
print("\nğŸ”„ Upgrade pip...")
!venv_py310/bin/pip install --upgrade pip --quiet

# CÃ i Ä‘áº·t dependencies vá»›i error handling
print("\nğŸ“¥ CÃ i Ä‘áº·t packages tá»« requirements.txt...")
print("   (QuÃ¡ trÃ¬nh nÃ y cÃ³ thá»ƒ máº¥t 10-20 phÃºt, vui lÃ²ng Ä‘á»£i...)")

# Import subprocess (náº¿u chÆ°a import)
import subprocess
import os

pip_process = subprocess.run(
    ["venv_py310/bin/pip", "install", "-r", "requirements.txt"],
    cwd=str(current_dir),
    capture_output=False,  # Hiá»ƒn thá»‹ output real-time
    text=True
)

if pip_process.returncode != 0:
    print("\nâŒ Lá»—i khi cÃ i Ä‘áº·t dependencies!")
    print("   Vui lÃ²ng cháº¡y láº¡i script tá»« Ä‘áº§u")
    print("   Hoáº·c cÃ i Ä‘áº·t thá»§ cÃ´ng: !venv_py310/bin/pip install -r requirements.txt")
    raise RuntimeError("Failed to install dependencies")

print("\nâœ… ÄÃ£ cÃ i Ä‘áº·t dependencies thÃ nh cÃ´ng!")

# Kiá»ƒm tra cÃ¡c packages quan trá»ng Ä‘Ã£ Ä‘Æ°á»£c cÃ i Ä‘áº·t
print("\nğŸ” Kiá»ƒm tra packages quan trá»ng...")
check_packages = """
import sys
sys.path.insert(0, 'venv_py310/lib/python3.10/site-packages')
packages = ['rasa', 'torch', 'transformers']
missing = []
for pkg in packages:
    try:
        __import__(pkg)
        print(f"âœ… {pkg}")
    except ImportError:
        print(f"âŒ {pkg} - CHÆ¯A CÃ€I Äáº¶T")
        missing.append(pkg)

if missing:
    sys.exit(1)
"""
with open("/tmp/check_packages.py", "w") as f:
    f.write(check_packages)

result = subprocess.run(
    ["venv_py310/bin/python", "/tmp/check_packages.py"],
    cwd=str(current_dir),
    capture_output=True,
    text=True
)

if result.returncode != 0:
    print(result.stdout)
    print("\nâŒ Má»™t sá»‘ packages quan trá»ng chÆ°a Ä‘Æ°á»£c cÃ i Ä‘áº·t!")
    print("   âš ï¸ Vui lÃ²ng cháº¡y láº¡i script tá»« Ä‘áº§u vÃ  Ä‘á»£i cÃ i Ä‘áº·t hoÃ n táº¥t")
    print("   âš ï¸ KHÃ”NG interrupt quÃ¡ trÃ¬nh cÃ i Ä‘áº·t (cÃ³ thá»ƒ máº¥t 10-20 phÃºt)")
    raise RuntimeError("Critical packages not installed")
else:
    print(result.stdout)
    print("âœ… Táº¥t cáº£ packages quan trá»ng Ä‘Ã£ Ä‘Æ°á»£c cÃ i Ä‘áº·t")

# BÆ°á»›c 4.5: Kiá»ƒm tra GPU (sau khi Ä‘Ã£ cÃ i Ä‘áº·t PyTorch)
print("\nğŸ® Kiá»ƒm tra GPU...")
print("=" * 60)

# Kiá»ƒm tra GPU báº±ng nvidia-smi
nvidia_result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)
if nvidia_result.returncode == 0:
    print("âœ… GPU Ä‘Æ°á»£c phÃ¡t hiá»‡n:")
    print(nvidia_result.stdout)
else:
    print("âŒ KhÃ´ng tÃ¬m tháº¥y GPU!")
    print("\nâš ï¸ QUAN TRá»ŒNG: Äá»ƒ sá»­ dá»¥ng GPU trÃªn Colab:")
    print("   1. VÃ o menu: Runtime â†’ Change runtime type")
    print("   2. Chá»n 'Hardware accelerator': GPU")
    print("   3. Chá»n GPU type: T4 (miá»…n phÃ­) hoáº·c A100/V100 (tráº£ phÃ­)")
    print("   4. Click 'Save'")
    print("   5. Cháº¡y láº¡i script tá»« Ä‘áº§u")
    print("\nğŸ’¡ Training sáº½ cháº¡y trÃªn CPU (cháº­m hÆ¡n) náº¿u khÃ´ng cÃ³ GPU")

# Kiá»ƒm tra PyTorch cÃ³ detect GPU khÃ´ng (sau khi Ä‘Ã£ cÃ i Ä‘áº·t)
print("\nğŸ” Kiá»ƒm tra PyTorch GPU support...")
check_gpu_script = """
import sys
import os
venv_path = os.path.join(os.getcwd(), 'venv_py310', 'lib', 'python3.10', 'site-packages')
sys.path.insert(0, venv_path)

try:
    import torch
    if torch.cuda.is_available():
        print(f"âœ… PyTorch phÃ¡t hiá»‡n GPU: {torch.cuda.get_device_name(0)}")
        print(f"   GPU Count: {torch.cuda.device_count()}")
        print(f"   CUDA Version: {torch.version.cuda}")
        print(f"   GPU Memory: {torch.cuda.get_device_properties(0).total_memory / (1024**3):.1f} GB")
    else:
        print("âŒ PyTorch KHÃ”NG phÃ¡t hiá»‡n GPU")
        print("   CÃ³ thá»ƒ do:")
        print("   1. ChÆ°a báº­t GPU runtime trÃªn Colab")
        print("   2. Hoáº·c Colab free tier khÃ´ng cÃ³ GPU available")
except ImportError as e:
    print(f"âš ï¸ PyTorch chÆ°a Ä‘Æ°á»£c cÃ i Ä‘áº·t: {e}")
    print("   Script sáº½ dá»«ng láº¡i - vui lÃ²ng cháº¡y láº¡i vÃ  Ä‘á»£i cÃ i Ä‘áº·t hoÃ n táº¥t")
    sys.exit(1)
"""
with open("/tmp/check_gpu.py", "w") as f:
    f.write(check_gpu_script)

gpu_check_result = subprocess.run(
    ["venv_py310/bin/python", "/tmp/check_gpu.py"],
    cwd=str(current_dir),
    capture_output=True,
    text=True
)

print(gpu_check_result.stdout)
if gpu_check_result.stderr:
    print(gpu_check_result.stderr)

if gpu_check_result.returncode != 0:
    print("\nâš ï¸ PyTorch chÆ°a Ä‘Æ°á»£c cÃ i Ä‘áº·t hoÃ n chá»‰nh")
    print("   Vui lÃ²ng cháº¡y láº¡i script tá»« Ä‘áº§u vÃ  Ä‘á»£i cÃ i Ä‘áº·t hoÃ n táº¥t")

print("=" * 60)

# BÆ°á»›c 5: Cáº­p nháº­t config Ä‘á»ƒ dÃ¹ng model online
print("\nâš™ï¸ Cáº­p nháº­t config...")

# Äáº£m báº£o Ä‘ang á»Ÿ Ä‘Ãºng thÆ° má»¥c root cá»§a project
current_dir = Path.cwd()
print(f"   ThÆ° má»¥c hiá»‡n táº¡i: {current_dir}")

# TÃ¬m file config (cÃ³ thá»ƒ á»Ÿ root hoáº·c trong config/rasa/)
config_paths = [
    current_dir / "config.yml",
    current_dir / "config/rasa/config.yml",
]

config_file = None
config_path_used = None

for path in config_paths:
    if path.exists():
        config_file = str(path)
        config_path_used = path
        print(f"   âœ… TÃ¬m tháº¥y config táº¡i: {path}")
        break

if not config_file:
    print("âŒ KhÃ´ng tÃ¬m tháº¥y config.yml")
    print("   Äang tÃ¬m trong:")
    for path in config_paths:
        exists = path.exists()
        print(f"   - {path} ({'tá»“n táº¡i' if exists else 'khÃ´ng tá»“n táº¡i'})")
        if exists:
            print(f"     Absolute: {path.resolve()}")
    raise FileNotFoundError("KhÃ´ng tÃ¬m tháº¥y config.yml")

# Náº¿u config á»Ÿ trong config/rasa/, copy vÃ o root Ä‘á»ƒ Rasa tÃ¬m tháº¥y
# Colab filesystem khÃ´ng há»— trá»£ symlink tá»‘t, nÃªn dÃ¹ng copy
root_config = current_dir / "config.yml"
rasa_config = current_dir / "config/rasa/config.yml"

if config_path_used == rasa_config:
    print(f"   Copy config tá»« {rasa_config} -> {root_config}")
    
    # XÃ³a file cÅ© náº¿u tá»“n táº¡i (ká»ƒ cáº£ broken symlink)
    # DÃ¹ng os.path.lexists Ä‘á»ƒ detect cáº£ broken symlink
    root_config_str = str(root_config)
    if os.path.lexists(root_config_str):
        try:
            # XÃ³a file/symlink (ká»ƒ cáº£ broken)
            if os.path.islink(root_config_str):
                os.unlink(root_config_str)
                print("   âœ… ÄÃ£ xÃ³a symlink cÅ©")
            else:
                os.remove(root_config_str)
                print("   âœ… ÄÃ£ xÃ³a file cÅ©")
        except Exception as e:
            print(f"   âš ï¸ KhÃ´ng thá»ƒ xÃ³a file cÅ©: {e}")
            # Thá»­ xÃ³a báº±ng shutil
            try:
                if os.path.isdir(root_config_str):
                    shutil.rmtree(root_config_str)
                else:
                    os.remove(root_config_str)
                print("   âœ… ÄÃ£ force xÃ³a file cÅ©")
            except Exception:
                pass
    
    # Copy file báº±ng shutil.copyfile (xá»­ lÃ½ tá»‘t hÆ¡n)
    try:
        shutil.copyfile(str(rasa_config), root_config_str)
        # Verify file Ä‘Ã£ Ä‘Æ°á»£c táº¡o
        if os.path.exists(root_config_str) and os.path.isfile(root_config_str):
            print("   âœ… ÄÃ£ copy config.yml vÃ o root")
            config_file = "config.yml"
        else:
            raise FileNotFoundError("File khÃ´ng tá»“n táº¡i sau khi copy")
    except Exception as e:
        print(f"   âŒ KhÃ´ng thá»ƒ copy file: {e}")
        print(f"   Source: {rasa_config} (exists: {rasa_config.exists()})")
        print(f"   Destination: {root_config_str}")
        print(f"   Current dir: {os.getcwd()}")
        raise FileNotFoundError(f"KhÃ´ng thá»ƒ táº¡o config.yml á»Ÿ root: {e}")

# Copy cÃ¡c file config khÃ¡c vÃ o root
rasa_config_files = ["domain.yml", "endpoints.yml", "credentials.yml"]
for filename in rasa_config_files:
    rasa_path = current_dir / "config/rasa" / filename
    root_path = current_dir / filename
    
    if rasa_path.exists():
        root_path_str = str(root_path)
        # XÃ³a file cÅ© náº¿u tá»“n táº¡i (ká»ƒ cáº£ broken symlink)
        if os.path.lexists(root_path_str):
            try:
                if os.path.islink(root_path_str):
                    os.unlink(root_path_str)
                else:
                    os.remove(root_path_str)
            except Exception:
                pass
        
        # Copy file báº±ng shutil
        try:
            shutil.copyfile(str(rasa_path), root_path_str)
            if os.path.exists(root_path_str) and os.path.isfile(root_path_str):
                print(f"   âœ… ÄÃ£ copy {filename} vÃ o root")
            else:
                print(f"   âš ï¸ File {filename} khÃ´ng tá»“n táº¡i sau khi copy")
        except Exception as e:
            print(f"   âš ï¸ KhÃ´ng thá»ƒ copy {filename}: {e}")

# Äá»c vÃ  cáº­p nháº­t config (Ä‘áº£m báº£o dÃ¹ng file á»Ÿ root)
config_to_update = current_dir / "config.yml"

# Äáº£m báº£o config.yml tá»“n táº¡i á»Ÿ root
if not config_to_update.exists():
    raise FileNotFoundError("config.yml khÃ´ng tá»“n táº¡i á»Ÿ root! Äáº£m báº£o Ä‘Ã£ copy file tá»« config/rasa/")

print(f"   Äang cáº­p nháº­t: {config_to_update}")

# Äá»c config
with open(config_to_update, "r", encoding="utf-8") as f:
    config = f.read()

# Cáº­p nháº­t config
config = re.sub(r'model_name:\s*"models/phobert-large"', 'model_name: "vinai/phobert-large"', config)
config = re.sub(r'cache_dir:\s*null', 'cache_dir: "models_hub/phobert_cache"', config)

# Ghi láº¡i config vÃ o root
with open(config_to_update, "w", encoding="utf-8") as f:
    f.write(config)

# CÅ©ng cáº­p nháº­t file gá»‘c trong config/rasa/ Ä‘á»ƒ Ä‘á»“ng bá»™
if rasa_config.exists():
    with open(rasa_config, "w", encoding="utf-8") as f:
        f.write(config)
    print("   âœ… ÄÃ£ cáº­p nháº­t cáº£ file gá»‘c trong config/rasa/")

print("âœ… ÄÃ£ cáº­p nháº­t config Ä‘á»ƒ dÃ¹ng model online")

# BÆ°á»›c 5.5: Tá»‘i Æ°u config dá»±a trÃªn GPU (náº¿u cÃ³)
print("\nâš¡ Tá»‘i Æ°u config Ä‘á»ƒ táº­n dá»¥ng GPU...")

# Kiá»ƒm tra GPU memory (sau khi PyTorch Ä‘Ã£ Ä‘Æ°á»£c cÃ i Ä‘áº·t)
gpu_memory_gb = None
try:
    check_gpu_memory = """
import sys
import os
# Add venv to path
venv_path = os.path.join(os.getcwd(), 'venv_py310', 'lib', 'python3.10', 'site-packages')
sys.path.insert(0, venv_path)

try:
    import torch
    if torch.cuda.is_available():
        gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)
        gpu_name = torch.cuda.get_device_name(0)
        print(f"{gpu_memory:.1f}|{gpu_name}")
    else:
        print("0|No GPU")
except ImportError as e:
    print(f"0|PyTorch not installed: {e}")
except Exception as e:
    print(f"0|Error: {e}")
"""
    with open("/tmp/check_gpu_memory.py", "w") as f:
        f.write(check_gpu_memory)
    
    result = subprocess.run(
        ["venv_py310/bin/python", "/tmp/check_gpu_memory.py"],
        capture_output=True,
        text=True,
        cwd=str(current_dir),
        timeout=30
    )
    
    if result.returncode == 0 and result.stdout.strip():
        output = result.stdout.strip()
        if "|" in output:
            parts = output.split("|")
            gpu_memory_gb = float(parts[0])
            gpu_name = parts[1] if len(parts) > 1 else "Unknown"
            if gpu_memory_gb > 0:
                print(f"   GPU: {gpu_name} ({gpu_memory_gb:.1f} GB)")
        else:
            # Fallback: try to parse as float
            try:
                gpu_memory_gb = float(output)
                if gpu_memory_gb > 0:
                    print(f"   GPU Memory: {gpu_memory_gb:.1f} GB")
            except ValueError:
                pass
    else:
        print(f"   âš ï¸ KhÃ´ng thá»ƒ kiá»ƒm tra GPU memory: {result.stderr}")
except subprocess.TimeoutExpired:
    print("   âš ï¸ Timeout khi kiá»ƒm tra GPU memory")
except Exception as e:
    print(f"   âš ï¸ KhÃ´ng thá»ƒ kiá»ƒm tra GPU memory: {e}")
    print("   ğŸ’¡ Sáº½ sá»­ dá»¥ng batch size máº·c Ä‘á»‹nh")

# Tá»‘i Æ°u batch size dá»±a trÃªn GPU memory
if gpu_memory_gb and gpu_memory_gb > 0:
    print(f"   GPU Memory: {gpu_memory_gb:.1f} GB")
    
    # Äá»c config
    config_file = current_dir / "config.yml"
    with open(config_file, "r", encoding="utf-8") as f:
        config_content = f.read()
    
    original_content = config_content
    
    # Tá»‘i Æ°u batch size dá»±a trÃªn GPU memory
    # LÆ°u Ã½: T4 thÆ°á»ng cÃ³ ~15GB nhÆ°ng cÃ³ thá»ƒ hiá»ƒn thá»‹ 14.7-14.9 GB, nÃªn coi >=14.5 GB lÃ  GPU lá»›n
    if gpu_memory_gb >= 14.5:  # T4 (~15GB), V100, A100
        # T4/V100/A100: CÃ³ thá»ƒ tÄƒng batch size lá»›n Ä‘á»ƒ táº­n dá»¥ng GPU
        print("   ğŸš€ GPU lá»›n phÃ¡t hiá»‡n (T4/V100/A100) - TÄƒng batch size Ä‘á»ƒ táº­n dá»¥ng GPU")
        print(f"   ğŸ’¡ GPU Memory: {gpu_memory_gb:.1f} GB - CÃ³ thá»ƒ tÄƒng batch size cao hÆ¡n")
        # Tá»‘i Æ°u PhoBERTFeaturizer batch_size (sau pooling_strategy)
        # Vá»›i T4 15GB, cÃ³ thá»ƒ tÄƒng lÃªn 128-256
        config_content = re.sub(
            r'(pooling_strategy:\s*"mean_max"\s*\n\s*batch_size:)\s*\d+(\s*#.*)?',
            r'\1 256  # Tá»‘i Æ°u cho GPU lá»›n (T4/V100/A100) - táº­n dá»¥ng GPU memory',
            config_content
        )
        # Tá»‘i Æ°u DIETClassifier batch_size - tÄƒng cao hÆ¡n Ä‘á»ƒ training nhanh hÆ¡n
        config_content = re.sub(
            r'(batch_size:\s*)\[16,\s*32\](\s*#.*)?',
            r'\1[256, 512]  # Tá»‘i Æ°u cho GPU lá»›n - training nhanh hÆ¡n',
            config_content
        )
        # Náº¿u cÃ³ pattern khÃ¡c nhÆ° [64, 128] tá»« láº§n tá»‘i Æ°u trÆ°á»›c, cÅ©ng cáº­p nháº­t
        config_content = re.sub(
            r'(batch_size:\s*)\[64,\s*128\](\s*#.*)?',
            r'\1[256, 512]  # Tá»‘i Æ°u cho GPU lá»›n - training nhanh hÆ¡n',
            config_content
        )
        config_content = re.sub(
            r'(batch_size:\s*)\[128,\s*256\](\s*#.*)?',
            r'\1[256, 512]  # Tá»‘i Æ°u cho GPU lá»›n - training nhanh hÆ¡n',
            config_content
        )
    elif gpu_memory_gb >= 8:  # P100, K80, hoáº·c GPU trung bÃ¬nh
        # GPU trung bÃ¬nh
        print("   âš¡ GPU trung bÃ¬nh phÃ¡t hiá»‡n - TÄƒng batch size vá»«a pháº£i")
        config_content = re.sub(
            r'(pooling_strategy:\s*"mean_max"\s*\n\s*batch_size:)\s*\d+(\s*#.*)?',
            r'\1 128  # Tá»‘i Æ°u cho GPU trung bÃ¬nh',
            config_content
        )
        config_content = re.sub(
            r'(batch_size:\s*)\[16,\s*32\](\s*#.*)?',
            r'\1[128, 256]  # Tá»‘i Æ°u cho GPU trung bÃ¬nh',
            config_content
        )
    elif gpu_memory_gb >= 4:  # GPU nhá»
        # GPU nhá»: giá»¯ nguyÃªn hoáº·c tÄƒng nháº¹
        print("   ğŸ“Š GPU nhá» phÃ¡t hiá»‡n - TÄƒng batch size nháº¹")
        config_content = re.sub(
            r'(pooling_strategy:\s*"mean_max"\s*\n\s*batch_size:)\s*\d+(\s*#.*)?',
            r'\1 48  # Tá»‘i Æ°u cho GPU nhá»',
            config_content
        )
        config_content = re.sub(
            r'(batch_size:\s*)\[16,\s*32\]',
            r'\1[32, 64]  # Tá»‘i Æ°u cho GPU nhá»',
            config_content
        )
    else:
        print("   â„¹ï¸ GPU memory nhá» - Giá»¯ batch size máº·c Ä‘á»‹nh")
    
    # Ghi láº¡i config náº¿u cÃ³ thay Ä‘á»•i
    if config_content != original_content:
        with open(config_file, "w", encoding="utf-8") as f:
            f.write(config_content)
        print("   âœ… ÄÃ£ tá»‘i Æ°u batch size trong config.yml")
        print("   ğŸ’¡ Batch size lá»›n hÆ¡n sáº½:")
        print("      - Sá»­ dá»¥ng GPU hiá»‡u quáº£ hÆ¡n")
        print("      - Training nhanh hÆ¡n (nhiá»u samples/batch)")
        print("      - Táº­n dá»¥ng GPU memory tá»‘t hÆ¡n")
        
        # CÅ©ng cáº­p nháº­t file gá»‘c trong config/rasa/ Ä‘á»ƒ Ä‘á»“ng bá»™
        rasa_config_path = current_dir / "config/rasa/config.yml"
        if rasa_config_path.exists():
            with open(rasa_config_path, "w", encoding="utf-8") as f:
                f.write(config_content)
            print("   âœ… ÄÃ£ cáº­p nháº­t cáº£ file gá»‘c trong config/rasa/")
    else:
        print("   â„¹ï¸ Config Ä‘Ã£ tá»‘i Æ°u hoáº·c khÃ´ng cáº§n thay Ä‘á»•i")
else:
    print("   â„¹ï¸ KhÃ´ng cÃ³ GPU hoáº·c khÃ´ng thá»ƒ detect GPU memory")
    print("   ğŸ’¡ Sáº½ sá»­ dá»¥ng batch size máº·c Ä‘á»‹nh (phÃ¹ há»£p cho CPU)")

# BÆ°á»›c 6: Train NLU
print("\nğŸš€ Báº¯t Ä‘áº§u training...")
print("ğŸ’¡ QuÃ¡ trÃ¬nh nÃ y cÃ³ thá»ƒ máº¥t 30 phÃºt - 2 giá»")
if gpu_memory_gb and gpu_memory_gb > 0:
    print(f"ğŸ’¡ GPU: {gpu_memory_gb:.1f} GB - Batch size Ä‘Ã£ Ä‘Æ°á»£c tá»‘i Æ°u")

# Äáº£m báº£o config.yml tá»“n táº¡i á»Ÿ root trÆ°á»›c khi train
if not (current_dir / "config.yml").exists():
    raise FileNotFoundError("config.yml khÃ´ng tá»“n táº¡i á»Ÿ root! KhÃ´ng thá»ƒ train.")

# Kiá»ƒm tra Rasa Ä‘Ã£ Ä‘Æ°á»£c cÃ i Ä‘áº·t trÆ°á»›c khi train
print("\nğŸ” Kiá»ƒm tra Rasa trÆ°á»›c khi train...")
check_rasa = """
import sys
import os
venv_path = os.path.join(os.getcwd(), 'venv_py310', 'lib', 'python3.10', 'site-packages')
sys.path.insert(0, venv_path)

try:
    import rasa
    print(f"âœ… Rasa version: {rasa.__version__}")
    sys.exit(0)
except ImportError as e:
    print(f"âŒ Rasa chÆ°a Ä‘Æ°á»£c cÃ i Ä‘áº·t: {e}")
    sys.exit(1)
"""

with open("/tmp/check_rasa.py", "w") as f:
    f.write(check_rasa)

rasa_check = subprocess.run(
    ["venv_py310/bin/python", "/tmp/check_rasa.py"],
    cwd=str(current_dir),
    capture_output=True,
    text=True
)

print(rasa_check.stdout)
if rasa_check.stderr:
    print(rasa_check.stderr)

if rasa_check.returncode != 0:
    print("\nâŒ Rasa chÆ°a Ä‘Æ°á»£c cÃ i Ä‘áº·t!")
    print("   âš ï¸ Vui lÃ²ng cháº¡y láº¡i script tá»« Ä‘áº§u vÃ  Ä‘á»£i cÃ i Ä‘áº·t hoÃ n táº¥t")
    print("   âš ï¸ KHÃ”NG interrupt quÃ¡ trÃ¬nh cÃ i Ä‘áº·t dependencies (cÃ³ thá»ƒ máº¥t 10-20 phÃºt)")
    raise RuntimeError("Rasa not installed - cannot proceed with training")

print("\nâœ… Rasa Ä‘Ã£ sáºµn sÃ ng - Báº¯t Ä‘áº§u training...\n")

# Train vá»›i config á»Ÿ root
train_process = subprocess.run(
    ["venv_py310/bin/python", "-m", "rasa", "train", "nlu", "--config", "config.yml"],
    cwd=str(current_dir),
    capture_output=False,  # Hiá»ƒn thá»‹ output real-time
    text=True
)

if train_process.returncode != 0:
    print("\nâŒ Training tháº¥t báº¡i!")
    print("   Vui lÃ²ng kiá»ƒm tra lá»—i á»Ÿ trÃªn vÃ  thá»­ láº¡i")
    raise RuntimeError("Training failed")

# BÆ°á»›c 7: Download model
print("\nğŸ“¥ Táº£i model vá» mÃ¡y...")
from google.colab import files

models = list(Path("models").glob("*.tar.gz"))
if models:
    latest = max(models, key=lambda x: x.stat().st_mtime)
    size_mb = latest.stat().st_size / (1024*1024)
    print(f"ğŸ“¦ Model: {latest.name} ({size_mb:.2f} MB)")
    files.download(str(latest))
    print("âœ… ÄÃ£ báº¯t Ä‘áº§u táº£i model vá» mÃ¡y")
else:
    print("âŒ KhÃ´ng tÃ¬m tháº¥y model")

print("\nğŸ‰ HoÃ n táº¥t!")

