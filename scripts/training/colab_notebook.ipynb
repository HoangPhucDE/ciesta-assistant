{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üöÄ Train Rasa NLU v·ªõi PhoBERT-large tr√™n Google Colab\n",
        "\n",
        "Notebook n√†y s·∫Ω t·ª± ƒë·ªông:\n",
        "1. C√†i ƒë·∫∑t dependencies\n",
        "2. T·∫£i PhoBERT-large model\n",
        "3. Train NLU model\n",
        "4. Download model v·ªÅ m√°y local\n",
        "\n",
        "## ‚ö†Ô∏è L∆∞u √Ω Quan Tr·ªçng\n",
        "\n",
        "**T√™n th∆∞ m·ª•c sau khi clone l√† `ciesta-assistant` (kh√¥ng ph·∫£i `ciesta-asisstant`)**\n",
        "\n",
        "## üìã Y√™u c·∫ßu\n",
        "- Clone repository t·ª´ GitHub\n",
        "- Ho·∫∑c upload c√°c file c·∫ßn thi·∫øt v√†o Colab\n",
        "\n",
        "## üîß C√°ch s·ª≠ d·ª•ng\n",
        "1. Ch·∫°y cell ƒë·∫ßu ti√™n ƒë·ªÉ clone repo\n",
        "2. Ch·∫°y c√°c cell ti·∫øp theo ƒë·ªÉ train\n",
        "3. Ch·ªù training ho√†n t·∫•t (30 ph√∫t - 2 gi·ªù)\n",
        "4. Model s·∫Ω t·ª± ƒë·ªông ƒë∆∞·ª£c t·∫£i v·ªÅ m√°y local\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## B∆∞·ªõc 1: Upload files (N·∫øu ch∆∞a c√≥ trong Colab)\n",
        "\n",
        "N·∫øu b·∫°n ƒë√£ clone repo th√¨ b·ªè qua b∆∞·ªõc n√†y.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Upload files n·∫øu c·∫ßn\n",
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## B∆∞·ªõc 2: Clone repository v√† Setup\n",
        "\n",
        "**QUAN TR·ªåNG:** T√™n th∆∞ m·ª•c l√† `ciesta-assistant` (kh√¥ng ph·∫£i `ciesta-asisstant`)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# SETUP T·ª∞ ƒê·ªòNG - CH·∫†Y CELL N√ÄY ƒê·∫¶U TI√äN\n",
        "# ============================================\n",
        "\n",
        "import os\n",
        "\n",
        "# B∆∞·ªõc 1: Clone repository\n",
        "if not os.path.exists(\"ciesta-assistant\"):\n",
        "    print(\"üì¶ ƒêang clone repository...\")\n",
        "    !git clone https://github.com/HoangPhucDE/ciesta-assistant.git\n",
        "    print(\"‚úÖ ƒê√£ clone repository th√†nh c√¥ng\")\n",
        "else:\n",
        "    print(\"‚úÖ Repository ƒë√£ t·ªìn t·∫°i\")\n",
        "\n",
        "# B∆∞·ªõc 2: Chuy·ªÉn v√†o th∆∞ m·ª•c\n",
        "%cd ciesta-assistant\n",
        "print(f\"‚úÖ ƒê√£ chuy·ªÉn v√†o: {os.getcwd()}\")\n",
        "\n",
        "# B∆∞·ªõc 3: Ki·ªÉm tra files c·∫ßn thi·∫øt\n",
        "print(\"\\nüìã Ki·ªÉm tra files c·∫ßn thi·∫øt:\")\n",
        "required_files = [\n",
        "    \"config.yml\",\n",
        "    \"data/nlu.yml\",\n",
        "    \"custom_components/phobert_featurizer.py\",\n",
        "    \"requirements.txt\"\n",
        "]\n",
        "\n",
        "missing = []\n",
        "for file in required_files:\n",
        "    if os.path.exists(file):\n",
        "        print(f\"  ‚úÖ {file}\")\n",
        "    else:\n",
        "        print(f\"  ‚ùå {file} - KH√îNG T√åM TH·∫§Y\")\n",
        "        missing.append(file)\n",
        "\n",
        "if missing:\n",
        "    print(f\"\\n‚ö† C·∫£nh b√°o: Thi·∫øu c√°c file: {', '.join(missing)}\")\n",
        "else:\n",
        "    print(\"\\n‚úÖ T·∫•t c·∫£ files c·∫ßn thi·∫øt ƒë√£ c√≥ s·∫µn!\")\n",
        "    print(\"\\nüöÄ S·∫µn s√†ng ƒë·ªÉ train! Ch·∫°y cell ti·∫øp theo ƒë·ªÉ b·∫Øt ƒë·∫ßu.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## B∆∞·ªõc 3: Ch·∫°y script training t·ª± ƒë·ªông\n",
        "\n",
        "Script s·∫Ω t·ª± ƒë·ªông:\n",
        "- C√†i ƒë·∫∑t dependencies\n",
        "- T·∫£i PhoBERT-large\n",
        "- Train NLU model\n",
        "- Download model v·ªÅ m√°y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ch·∫°y script training\n",
        "!python scripts/training/train_on_colab.py\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## B∆∞·ªõc 4: Training th·ªß c√¥ng (N·∫øu c·∫ßn)\n",
        "\n",
        "N·∫øu script t·ª± ƒë·ªông kh√¥ng ho·∫°t ƒë·ªông, b·∫°n c√≥ th·ªÉ ch·∫°y t·ª´ng b∆∞·ªõc th·ªß c√¥ng:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# C√†i ƒë·∫∑t dependencies\n",
        "%pip install -q -r requirements.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# T·∫£i PhoBERT-large model\n",
        "from huggingface_hub import snapshot_download\n",
        "import os\n",
        "\n",
        "os.makedirs(\"models_hub/phobert-large\", exist_ok=True)\n",
        "\n",
        "snapshot_download(\n",
        "    repo_id=\"vinai/phobert-large\",\n",
        "    local_dir=\"models_hub/phobert-large\",\n",
        "    local_dir_use_symlinks=False,\n",
        "    resume_download=True\n",
        ")\n",
        "\n",
        "print(\"‚úÖ ƒê√£ t·∫£i model th√†nh c√¥ng\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# T·∫°o symlink ho·∫∑c copy model\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "os.makedirs(\"models\", exist_ok=True)\n",
        "\n",
        "if os.path.exists(\"models/phobert-large\"):\n",
        "    if os.path.islink(\"models/phobert-large\"):\n",
        "        os.unlink(\"models/phobert-large\")\n",
        "    else:\n",
        "        shutil.rmtree(\"models/phobert-large\")\n",
        "\n",
        "try:\n",
        "    os.symlink(\"../models_hub/phobert-large\", \"models/phobert-large\")\n",
        "    print(\"‚úÖ ƒê√£ t·∫°o symlink\")\n",
        "except:\n",
        "    shutil.copytree(\"models_hub/phobert-large\", \"models/phobert-large\")\n",
        "    print(\"‚úÖ ƒê√£ copy model\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train NLU model\n",
        "!rasa train nlu\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download model v·ªÅ m√°y local\n",
        "from google.colab import files\n",
        "from pathlib import Path\n",
        "\n",
        "models_dir = Path(\"models\")\n",
        "model_files = list(models_dir.glob(\"*.tar.gz\"))\n",
        "\n",
        "if model_files:\n",
        "    # Get latest model\n",
        "    latest_model = max(model_files, key=lambda x: x.stat().st_mtime)\n",
        "    print(f\"üì¶ Model m·ªõi nh·∫•t: {latest_model.name}\")\n",
        "    print(f\"üìä K√≠ch th∆∞·ªõc: {latest_model.stat().st_size / (1024*1024):.2f} MB\")\n",
        "    \n",
        "    files.download(str(latest_model))\n",
        "    print(\"‚úÖ ƒê√£ b·∫Øt ƒë·∫ßu t·∫£i model v·ªÅ m√°y\")\n",
        "else:\n",
        "    print(\"‚ùå Kh√¥ng t√¨m th·∫•y model\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîç Troubleshooting\n",
        "\n",
        "### L·ªói: Out of Memory\n",
        "- Gi·∫£m `batch_size` trong `config.yml`\n",
        "  ```yaml\n",
        "  batch_size: [8, 16]  # Thay v√¨ [16, 32]\n",
        "  ```\n",
        "\n",
        "### L·ªói: Training qu√° l√¢u\n",
        "- Gi·∫£m `epochs` trong `config.yml`\n",
        "  ```yaml\n",
        "  epochs: 300  # Thay v√¨ 600\n",
        "  ```\n",
        "\n",
        "### L·ªói: Kh√¥ng t√¨m th·∫•y model\n",
        "- Ki·ªÉm tra ƒë∆∞·ªùng d·∫´n trong `config.yml`:\n",
        "  ```yaml\n",
        "  model_name: \"models/phobert-large\"\n",
        "  ```\n",
        "\n",
        "### L·ªói: Import error\n",
        "- Ch·∫°y l·∫°i cell c√†i ƒë·∫∑t dependencies\n",
        "- Ki·ªÉm tra `requirements.txt` c√≥ ƒë·∫ßy ƒë·ªß kh√¥ng\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
