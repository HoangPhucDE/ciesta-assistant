#!/usr/bin/env python3
"""
Script ƒë·ªÉ ki·ªÉm tra nlu.yml sau khi sync_location_names.py
- Ki·ªÉm tra entities c√≥ trong knowledge base kh√¥ng
- Ki·ªÉm tra entities c√≥ format ƒë√∫ng kh√¥ng
- Ki·ªÉm tra entities c√≥ th·ªÉ g√¢y warning
"""

import json
import re
from pathlib import Path
from typing import Dict, Set, List

def load_provinces_from_kb(kb_dir: Path) -> Set[str]:
    """Load t√™n t·ªânh ch√≠nh th·ª©c t·ª´ knowledge base"""
    provinces = set()
    
    if not kb_dir.exists():
        return provinces
    
    for json_file in kb_dir.glob("*.json"):
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                if data:
                    canonical_name = list(data.keys())[0]
                    provinces.add(canonical_name)
        except Exception:
            pass
    
    return provinces

def check_entity_in_text(entity_value: str, text: str) -> bool:
    """
    Ki·ªÉm tra xem entity value c√≥ xu·∫•t hi·ªán trong text kh√¥ng
    (sau khi thay th·∫ø annotation b·∫±ng value)
    """
    # Lo·∫°i b·ªè c√°c k√Ω t·ª± ƒë·∫∑c bi·ªát ·ªü ƒë·∫ßu/cu·ªëi text (nh∆∞ d·∫•u ph·∫©y, d·∫•u ch·∫•m)
    import string
    punctuation = string.punctuation + '.,;:!?„ÄÇÔºåÔºõÔºöÔºÅÔºü'
    
    # Tokenize text
    tokens = text.split()
    entity_tokens = entity_value.split()
    
    # Ki·ªÉm tra exact match (case insensitive, kh√¥ng t√≠nh punctuation)
    entity_clean = entity_value.lower().strip(punctuation).strip()
    text_lower = text.lower()
    
    # T√¨m entity trong text (c√≥ th·ªÉ c√≥ punctuation xung quanh)
    if entity_clean in text_lower:
        # Ki·ªÉm tra xem c√≥ kh·ªõp v·ªõi token boundaries kh√¥ng
        for i in range(len(tokens) - len(entity_tokens) + 1):
            token_slice = ' '.join(tokens[i:i+len(entity_tokens)])
            token_slice_clean = token_slice.lower().strip(punctuation).strip()
            if token_slice_clean == entity_clean:
                return True
    
    # N·∫øu kh√¥ng t√¨m th·∫•y exact match, ki·ªÉm tra v·ªõi c√°c bi·∫øn th·ªÉ
    # (v√≠ d·ª•: "ƒê√† N·∫µng" c√≥ th·ªÉ xu·∫•t hi·ªán trong text nh∆∞ "ƒë√† n·∫µng")
    entity_words = entity_clean.split()
    if len(entity_words) > 0:
        # T√¨m t·ª´ng t·ª´ c·ªßa entity trong text
        all_words_found = True
        for word in entity_words:
            if word not in text_lower:
                all_words_found = False
                break
        
        if all_words_found:
            # Ki·ªÉm tra xem c√°c t·ª´ c√≥ xu·∫•t hi·ªán li√™n ti·∫øp kh√¥ng
            text_words = text_lower.split()
            for i in range(len(text_words) - len(entity_words) + 1):
                text_slice = text_words[i:i+len(entity_words)]
                if ' '.join(text_slice).strip(punctuation).strip() == entity_clean:
                    return True
    
    return False

def check_nlu_file(nlu_file: Path, kb_dir: Path) -> Dict:
    """Ki·ªÉm tra nlu.yml file"""
    results = {
        'total_examples': 0,
        'total_entities': 0,
        'entities_in_kb': 0,
        'entities_not_in_kb': set(),
        'potential_warnings': [],
        'format_issues': [],
    }
    
    # Load provinces t·ª´ KB
    provinces = load_provinces_from_kb(kb_dir)
    print(f"‚úÖ Loaded {len(provinces)} provinces from knowledge base")
    
    # ƒê·ªçc nlu.yml
    if not nlu_file.exists():
        print(f"‚úó Kh√¥ng t√¨m th·∫•y file: {nlu_file}")
        return results
    
    with open(nlu_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    lines = content.split('\n')
    entity_pattern = r'\[([^\]]+)\]\(location\)'
    
    # T√¨m t·∫•t c·∫£ entities
    all_entities = re.findall(entity_pattern, content)
    results['total_entities'] = len(all_entities)
    unique_entities = set(all_entities)
    
    # Ki·ªÉm tra t·ª´ng entity
    for entity_value in unique_entities:
        if entity_value in provinces:
            results['entities_in_kb'] += all_entities.count(entity_value)
        else:
            results['entities_not_in_kb'].add(entity_value)
            results['total_entities'] -= all_entities.count(entity_value)  # ƒê√£ ƒë·∫øm r·ªìi, kh√¥ng tr·ª´ l·∫°i
    
    # Ki·ªÉm tra t·ª´ng d√≤ng ƒë·ªÉ t√¨m potential warnings
    for line_num, line in enumerate(lines, 1):
        if line.strip().startswith('- ') and '[' in line and '](' in line:
            example = line[2:].strip()
            results['total_examples'] += 1
            
            # T√¨m entities
            entities = re.findall(entity_pattern, example)
            
            if entities:
                # Thay th·∫ø annotations b·∫±ng values ƒë·ªÉ c√≥ text thu·∫ßn
                text_with_values = example
                for match in entities:
                    if isinstance(match, tuple):
                        entity_value, entity_type = match
                    else:
                        entity_value = match
                        entity_type = 'location'
                    
                    text_with_values = re.sub(
                        rf'\[{re.escape(entity_value)}\]\(location\)',
                        entity_value,
                        text_with_values,
                        count=1
                    )
                
                # Ki·ªÉm tra t·ª´ng entity
                # entities l√† list of tuples (entity_value, entity_type) t·ª´ re.findall
                for match in entities:
                    if isinstance(match, tuple):
                        entity_value, entity_type = match
                    else:
                        entity_value = match
                        entity_type = 'location'
                    
                    # Ki·ªÉm tra xem entity value c√≥ trong text kh√¥ng
                    if not check_entity_in_text(entity_value, text_with_values):
                        results['potential_warnings'].append({
                            'line': line_num,
                            'example': example[:80],
                            'entity_value': entity_value,
                            'text_with_values': text_with_values[:80],
                        })
    
    return results

def check_format_issues(entities: Set[str]) -> List[str]:
    """Ki·ªÉm tra c√°c v·∫•n ƒë·ªÅ v·ªÅ format"""
    issues = []
    
    # Ki·ªÉm tra entities kh√¥ng c√≥ d·∫•u (c√≥ th·ªÉ l√† typo)
    common_typos = {
        'Hai Phong': 'H·∫£i Ph√≤ng',
        'Thua Thien Hue': 'Th·ª´a Thi√™n Hu·∫ø',
    }
    
    for entity in entities:
        if entity in common_typos:
            issues.append(f"‚ö†Ô∏è  '{entity}' c√≥ th·ªÉ l√† typo c·ªßa '{common_typos[entity]}'")
    
    return issues

def main():
    """Main function"""
    print("=" * 60)
    print("KI·ªÇM TRA NLU.YML SAU KHI SYNC LOCATION NAMES")
    print("=" * 60)
    print()
    
    # T√¨m project root (c√≥ th·ªÉ ch·∫°y t·ª´ project root ho·∫∑c t·ª´ scripts/training/utils)
    current_dir = Path.cwd()
    project_root = None
    
    # Th·ª≠ c√°c v·ªã tr√≠ c√≥ th·ªÉ
    possible_roots = [
        current_dir,  # ƒêang ·ªü project root
        current_dir.parent.parent.parent,  # ƒêang ·ªü scripts/training/utils
        current_dir.parent.parent,  # ƒêang ·ªü scripts/training
        current_dir.parent,  # ƒêang ·ªü scripts
    ]
    
    for possible_root in possible_roots:
        kb_dir = possible_root / "data" / "knowledge_base" / "provinces"
        if kb_dir.exists():
            project_root = possible_root
            break
    
    if not project_root:
        print("‚úó Kh√¥ng t√¨m th·∫•y project root (c·∫ßn data/knowledge_base/provinces)")
        return False
    
    print(f"üìÅ Project root: {project_root}")
    
    # Ki·ªÉm tra nlu.yml
    nlu_file = project_root / "data" / "nlu.yml"
    kb_dir = project_root / "data" / "knowledge_base" / "provinces"
    
    print(f"\nüîç Ki·ªÉm tra: {nlu_file}")
    results = check_nlu_file(nlu_file, kb_dir)
    
    # In k·∫øt qu·∫£
    print(f"\nüìä K·∫æT QU·∫¢ KI·ªÇM TRA:")
    print(f"   T·ªïng s·ªë examples: {results['total_examples']}")
    print(f"   T·ªïng s·ªë location entities: {results['total_entities']}")
    print(f"   Entities c√≥ trong KB: {results['entities_in_kb']}")
    print(f"   Entities kh√¥ng c√≥ trong KB: {len(results['entities_not_in_kb'])}")
    
    # Ki·ªÉm tra format issues
    format_issues = check_format_issues(results['entities_not_in_kb'])
    if format_issues:
        print(f"\n‚ö†Ô∏è  FORMAT ISSUES:")
        for issue in format_issues:
            print(f"   {issue}")
    
    # Entities kh√¥ng c√≥ trong KB
    if results['entities_not_in_kb']:
        print(f"\n‚ö†Ô∏è  ENTITIES KH√îNG C√ì TRONG KNOWLEDGE BASE:")
        print("   (C√≥ th·ªÉ l√† t√™n th√†nh ph·ªë/ƒë·ªãa danh con, kh√¥ng ph·∫£i t·ªânh)")
        
        # ƒê·∫øm s·ªë l·∫ßn xu·∫•t hi·ªán
        entity_counts = {}
        with open(nlu_file, 'r', encoding='utf-8') as f:
            content = f.read()
            entity_pattern = r'\[([^\]]+)\]\(location\)'
            all_entities = re.findall(entity_pattern, content)
            for entity in results['entities_not_in_kb']:
                entity_counts[entity] = all_entities.count(entity)
        
        # S·∫Øp x·∫øp theo s·ªë l·∫ßn xu·∫•t hi·ªán
        sorted_entities = sorted(entity_counts.items(), key=lambda x: x[1], reverse=True)
        
        for entity, count in sorted_entities[:20]:  # Ch·ªâ hi·ªÉn th·ªã 20 ƒë·∫ßu ti√™n
            print(f"   - {entity}: {count} l·∫ßn")
        
        if len(sorted_entities) > 20:
            print(f"   ... v√† {len(sorted_entities) - 20} entities kh√°c")
    
    # Potential warnings
    if results['potential_warnings']:
        print(f"\n‚ö†Ô∏è  POTENTIAL WARNINGS ({len(results['potential_warnings'])}):")
        print("   (Entity value kh√¥ng kh·ªõp v·ªõi text th·ª±c t·∫ø)")
        
        for i, warning in enumerate(results['potential_warnings'][:10], 1):
            print(f"\n   {i}. Line {warning['line']}:")
            print(f"      Example: {warning['example']}")
            print(f"      Entity: '{warning['entity_value']}'")
            print(f"      Text: {warning['text_with_values']}")
    else:
        print(f"\n‚úÖ KH√îNG C√ì POTENTIAL WARNINGS!")
        print("   T·∫•t c·∫£ entity values kh·ªõp v·ªõi text th·ª±c t·∫ø")
    
    # K·∫øt lu·∫≠n
    print("\n" + "=" * 60)
    if results['potential_warnings']:
        print("‚ö†Ô∏è  C√ì TH·ªÇ C√ì WARNINGS KHI TRAIN")
        print("   Vui l√≤ng ki·ªÉm tra c√°c entities kh√¥ng kh·ªõp v·ªõi text")
    else:
        print("‚úÖ KH√îNG C√ì WARNINGS!")
        print("   T·∫•t c·∫£ entities ƒë·ªÅu kh·ªõp v·ªõi text th·ª±c t·∫ø")
    print("=" * 60)
    
    return len(results['potential_warnings']) == 0

if __name__ == "__main__":
    import sys
    
    try:
        success = main()
        sys.exit(0 if success else 1)
    except Exception as e:
        print(f"‚úó L·ªói: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

