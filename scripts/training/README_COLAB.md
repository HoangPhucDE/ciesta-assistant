# ğŸš€ HÆ°á»›ng dáº«n Train trÃªn Google Colab

HÆ°á»›ng dáº«n chi tiáº¿t Ä‘á»ƒ train Rasa NLU model vá»›i PhoBERT-large trÃªn Google Colab.

## ğŸ“‹ YÃªu cáº§u

1. **Google Colab account** (miá»…n phÃ­)
2. **Files cáº§n thiáº¿t**:
   - `config.yml`
   - `data/nlu.yml`
   - `domain.yml`
   - `custom_components/phobert_featurizer.py`
   - `custom_components/vietnamese_preprocessor.py`
   - `requirements.txt`
   - `actions/actions.py` (náº¿u cÃ³)

## ğŸ¯ CÃ¡ch 1: Sá»­ dá»¥ng Script Tá»± Äá»™ng (Khuyáº¿n nghá»‹)

### BÆ°á»›c 1: Má»Ÿ Google Colab

1. Truy cáº­p: https://colab.research.google.com/
2. Táº¡o notebook má»›i hoáº·c má»Ÿ `colab_notebook.ipynb`

### BÆ°á»›c 2: Upload Files

**CÃ¡ch A: Clone tá»« Git (Khuyáº¿n nghá»‹)**

```python
# Cháº¡y trong cell Ä‘áº§u tiÃªn
!git clone https://github.com/HoangPhucDE/ciesta-assistant.git
%cd ciesta-assistant
```

**LÆ°u Ã½:** TÃªn thÆ° má»¥c sau khi clone lÃ  `ciesta-assistant` (khÃ´ng pháº£i `ciesta-asisstant`)

**CÃ¡ch B: Upload thá»§ cÃ´ng**

1. Upload táº¥t cáº£ files cáº§n thiáº¿t vÃ o Colab
2. Sá»­ dá»¥ng file browser bÃªn trÃ¡i Ä‘á»ƒ upload

### BÆ°á»›c 3: Cháº¡y Script Tá»± Äá»™ng

```python
# Cháº¡y script training tá»± Ä‘á»™ng
!python scripts/training/train_on_colab.py
```

Script sáº½ tá»± Ä‘á»™ng:
- âœ… CÃ i Ä‘áº·t dependencies
- âœ… Táº£i PhoBERT-large model
- âœ… Setup custom components
- âœ… Train NLU model
- âœ… Download model vá» mÃ¡y local

## ğŸ¯ CÃ¡ch 2: Training Thá»§ CÃ´ng

### BÆ°á»›c 1: CÃ i Ä‘áº·t Dependencies

```python
!pip install -q -r requirements.txt
```

### BÆ°á»›c 2: Táº£i PhoBERT-large Model

```python
from huggingface_hub import snapshot_download
import os

os.makedirs("models_hub/phobert-large", exist_ok=True)

snapshot_download(
    repo_id="vinai/phobert-large",
    local_dir="models_hub/phobert-large",
    local_dir_use_symlinks=False,
    resume_download=True
)

print("âœ… ÄÃ£ táº£i model thÃ nh cÃ´ng")
```

### BÆ°á»›c 3: Setup Model Path

```python
import os
import shutil

os.makedirs("models", exist_ok=True)

# Táº¡o symlink hoáº·c copy
if os.path.exists("models/phobert-large"):
    if os.path.islink("models/phobert-large"):
        os.unlink("models/phobert-large")
    else:
        shutil.rmtree("models/phobert-large")

try:
    os.symlink("../models_hub/phobert-large", "models/phobert-large")
    print("âœ… ÄÃ£ táº¡o symlink")
except:
    shutil.copytree("models_hub/phobert-large", "models/phobert-large")
    print("âœ… ÄÃ£ copy model")
```

### BÆ°á»›c 4: Kiá»ƒm tra Config

Äáº£m báº£o `config.yml` cÃ³ cáº¥u hÃ¬nh:

```yaml
- name: custom_components.phobert_featurizer.PhoBERTFeaturizer
  model_name: "models/phobert-large"
  cache_dir: null
  max_length: 256
  pooling_strategy: "mean_max"
```

### BÆ°á»›c 5: Train NLU Model

```python
!rasa train nlu
```

### BÆ°á»›c 6: Download Model

```python
from google.colab import files
from pathlib import Path

models_dir = Path("models")
model_files = list(models_dir.glob("*.tar.gz"))

if model_files:
    # Get latest model
    latest_model = max(model_files, key=lambda x: x.stat().st_mtime)
    print(f"ğŸ“¦ Model má»›i nháº¥t: {latest_model.name}")
    print(f"ğŸ“Š KÃ­ch thÆ°á»›c: {latest_model.stat().st_size / (1024*1024):.2f} MB")
    
    files.download(str(latest_model))
    print("âœ… ÄÃ£ báº¯t Ä‘áº§u táº£i model vá» mÃ¡y")
else:
    print("âŒ KhÃ´ng tÃ¬m tháº¥y model")
```

## ğŸ”§ Tá»‘i Æ¯u HÃ³a cho Colab

### Sá»­ dá»¥ng GPU (Khuyáº¿n nghá»‹)

1. VÃ o `Runtime` â†’ `Change runtime type`
2. Chá»n `GPU` (T4 hoáº·c tá»‘t hÆ¡n)
3. Training sáº½ nhanh hÆ¡n 5-10 láº§n

### Giáº£m Memory Usage

Náº¿u gáº·p lá»—i Out of Memory, chá»‰nh sá»­a `config.yml`:

```yaml
- name: DIETClassifier
  batch_size: [8, 16]  # Giáº£m tá»« [16, 32]
  epochs: 300          # Giáº£m tá»« 600
```

### TÄƒng tá»‘c Training

```yaml
- name: DIETClassifier
  epochs: 400          # Giáº£m epochs Ä‘á»ƒ train nhanh hÆ¡n
  batch_size: [32, 64] # TÄƒng batch size náº¿u cÃ³ GPU
```

## ğŸ” Troubleshooting

### Lá»—i: Out of Memory

**Giáº£i phÃ¡p:**
1. Giáº£m `batch_size` trong `config.yml`
2. Giáº£m `epochs`
3. Sá»­ dá»¥ng PhoBERT-base thay vÃ¬ Large

### Lá»—i: Training quÃ¡ lÃ¢u

**Giáº£i phÃ¡p:**
1. Sá»­ dá»¥ng GPU
2. Giáº£m `epochs` xuá»‘ng 300-400
3. Giáº£m `batch_size`

### Lá»—i: KhÃ´ng tÃ¬m tháº¥y model

**Giáº£i phÃ¡p:**
1. Kiá»ƒm tra Ä‘Æ°á»ng dáº«n trong `config.yml`
2. Äáº£m báº£o model Ä‘Ã£ Ä‘Æ°á»£c táº£i vÃ o `models_hub/phobert-large`
3. Kiá»ƒm tra symlink hoáº·c copy Ä‘Ã£ táº¡o chÆ°a

### Lá»—i: Import error

**Giáº£i phÃ¡p:**
1. Cháº¡y láº¡i cell cÃ i Ä‘áº·t dependencies
2. Kiá»ƒm tra `requirements.txt` cÃ³ Ä‘áº§y Ä‘á»§ khÃ´ng
3. Restart runtime: `Runtime` â†’ `Restart runtime`

### Lá»—i: Cannot find custom component

**Giáº£i phÃ¡p:**
1. Äáº£m báº£o `custom_components/phobert_featurizer.py` Ä‘Ã£ Ä‘Æ°á»£c upload
2. Kiá»ƒm tra `custom_components/__init__.py` cÃ³ tá»“n táº¡i khÃ´ng
3. Táº¡o file `__init__.py` náº¿u chÆ°a cÃ³:
   ```python
   # custom_components/__init__.py
   # File nÃ y Ä‘á»ƒ Python nháº­n diá»‡n thÆ° má»¥c lÃ  package
   ```

## ğŸ“Š Thá»i Gian Training

- **CPU**: 1-2 giá» (600 epochs)
- **GPU T4**: 20-40 phÃºt (600 epochs)
- **GPU V100**: 15-30 phÃºt (600 epochs)

## âœ… Checklist

TrÆ°á»›c khi train, Ä‘áº£m báº£o:

- [ ] ÄÃ£ upload táº¥t cáº£ files cáº§n thiáº¿t
- [ ] ÄÃ£ cÃ i Ä‘áº·t dependencies
- [ ] ÄÃ£ táº£i PhoBERT-large model
- [ ] ÄÃ£ táº¡o symlink/copy model
- [ ] ÄÃ£ kiá»ƒm tra config.yml
- [ ] ÄÃ£ báº­t GPU (náº¿u cÃ³)
- [ ] ÄÃ£ kiá»ƒm tra custom components

## ğŸ“ Notes

- Colab cÃ³ giá»›i háº¡n thá»i gian sá»­ dá»¥ng (12 giá» cho free tier)
- Model sáº½ bá»‹ xÃ³a sau khi Ä‘Ã³ng Colab
- Nhá»› download model vá» mÃ¡y local sau khi train xong
- CÃ³ thá»ƒ lÆ°u model lÃªn Google Drive Ä‘á»ƒ backup

## ğŸ”— Links Há»¯u Ãch

- [Google Colab](https://colab.research.google.com/)
- [Rasa Documentation](https://rasa.com/docs/)
- [PhoBERT HuggingFace](https://huggingface.co/vinai/phobert-large)


