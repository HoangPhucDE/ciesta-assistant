#!/usr/bin/env python3
"""
Script t·ª± ƒë·ªông train Rasa NLU model tr√™n Google Colab
- T·ª± ƒë·ªông cleanup v√† clone repo m·ªõi t·ª´ git (Colab only)
- T·ª± ƒë·ªông setup m√¥i tr∆∞·ªùng
- Download PhoBERT-large model
- Train NLU model
- Download model v·ªÅ m√°y local

Workflow (Colab):
1. Script t·ª± ƒë·ªông x√≥a repo c≈© v√† clone repo m·ªõi t·ª´ git
2. (Khuy·∫øn ngh·ªã) Ch·∫°y sync_location_names.py tr∆∞·ªõc ƒë·ªÉ ƒë·ªìng b·ªô location names
3. Ch·∫°y script n√†y ƒë·ªÉ train model
4. Model s·∫Ω ƒë∆∞·ª£c l∆∞u trong models/ v√† c√≥ th·ªÉ download v·ªÅ m√°y local

L∆∞u √Ω:
- Tr√™n Colab: Script t·ª± ƒë·ªông cleanup v√† clone repo m·ªõi m·ªói l·∫ßn ch·∫°y
- C√≥ th·ªÉ set CIESTA_GIT_URL v√† CIESTA_GIT_BRANCH ƒë·ªÉ clone branch kh√°c
- Script n√†y ch·ªâ ph·ª•c v·ª• training, kh√¥ng fix entity alignments
- Entity alignments n√™n ƒë∆∞·ª£c fix tr∆∞·ªõc b·∫±ng sync_location_names.py
- Xem docs/README_SYNC_LOCATIONS.md ƒë·ªÉ bi·∫øt th√™m chi ti·∫øt
"""

import os
import sys
import subprocess
import shutil
from pathlib import Path
from typing import Optional
import time
import re

# Colors for output
class Colors:
    HEADER = '\033[95m'
    OKBLUE = '\033[94m'
    OKCYAN = '\033[96m'
    OKGREEN = '\033[92m'
    WARNING = '\033[93m'
    FAIL = '\033[91m'
    ENDC = '\033[0m'
    BOLD = '\033[1m'
    UNDERLINE = '\033[4m'

def print_header(text: str):
    """Print header with color"""
    print(f"\n{Colors.HEADER}{Colors.BOLD}{'='*60}{Colors.ENDC}")
    print(f"{Colors.HEADER}{Colors.BOLD}{text}{Colors.ENDC}")
    print(f"{Colors.HEADER}{Colors.BOLD}{'='*60}{Colors.ENDC}\n")

def print_success(text: str):
    """Print success message"""
    print(f"{Colors.OKGREEN}‚úì {text}{Colors.ENDC}")

def print_error(text: str):
    """Print error message"""
    print(f"{Colors.FAIL}‚úó {text}{Colors.ENDC}")

def print_warning(text: str):
    """Print warning message"""
    print(f"{Colors.WARNING}‚ö† {text}{Colors.ENDC}")

def print_info(text: str):
    """Print info message"""
    print(f"{Colors.OKCYAN}‚Ñπ {text}{Colors.ENDC}")

def is_colab() -> bool:
    """Check if running on Google Colab"""
    try:
        import importlib.util
        return importlib.util.find_spec('google.colab') is not None
    except (ImportError, AttributeError):
        return False

def check_gpu() -> bool:
    """Check if GPU is available"""
    try:
        import torch
        return torch.cuda.is_available()
    except ImportError:
        return False

def find_project_root():
    """Find project root directory (ciesta-assistant or current dir)"""
    current_dir = Path.cwd()
    
    # Check if we're already in project root (check for key files)
    if (current_dir / "requirements.txt").exists() and (current_dir / "config.yml").exists():
        # Make sure we're not in a nested ciesta-assistant
        if "ciesta-assistant" in str(current_dir) and (current_dir.parent / "ciesta-assistant").exists():
            # We're in a nested directory, go up one level
            parent = current_dir.parent
            if (parent / "requirements.txt").exists() and (parent / "config.yml").exists():
                return parent
        return current_dir
    
    # Check if ciesta-assistant directory exists in current dir
    if (current_dir / "ciesta-assistant").exists():
        project_root = current_dir / "ciesta-assistant"
        # Check if it has the required files and is not nested
        if (project_root / "requirements.txt").exists() and (project_root / "config.yml").exists():
            # Make sure there's no nested ciesta-assistant inside
            nested = project_root / "ciesta-assistant"
            if nested.exists() and (nested / "requirements.txt").exists():
                # There's a nested one, use the outer one
                pass
            return project_root
    
    # Check parent directory
    if (current_dir.parent / "ciesta-assistant").exists():
        project_root = current_dir.parent / "ciesta-assistant"
        if (project_root / "requirements.txt").exists() and (project_root / "config.yml").exists():
            return project_root
    
    # Try to find in current and parent directories
    for possible_root in [current_dir, current_dir.parent]:
        if (possible_root / "requirements.txt").exists() and (possible_root / "config.yml").exists():
            return possible_root
    
    return None

def check_python_version():
    """Check Python version and warn if incompatible"""
    import sys
    version = sys.version_info
    version_str = f"{version.major}.{version.minor}.{version.micro}"
    
    print_info(f"Python version: {version_str}")
    
    # Rasa 3.6.20 requires Python 3.8-3.10
    if version.major == 3 and version.minor > 10:
        print_warning(f"Python {version_str} c√≥ th·ªÉ kh√¥ng t∆∞∆°ng th√≠ch v·ªõi Rasa 3.6.20")
        print_warning("Rasa 3.6.20 y√™u c·∫ßu Python 3.8-3.10")
        print_info("ƒêang ki·ªÉm tra Rasa version t∆∞∆°ng th√≠ch...")
        return False
    return True

def install_dependencies():
    """Install required dependencies"""
    print_header("C√ÄI ƒê·∫∂T DEPENDENCIES")
    
    # Check Python version first
    python_ok = check_python_version()
    
    # Find project root - but avoid nested directories
    current_dir = Path.cwd()
    project_root = None
    
    # Count how many times "ciesta-assistant" appears in path
    path_str = str(current_dir)
    ciesta_count = path_str.count("ciesta-assistant")
    
    if ciesta_count > 1:
        print_warning(f"Ph√°t hi·ªán nested directory (ciesta-assistant xu·∫•t hi·ªán {ciesta_count} l·∫ßn)")
        # Find the first occurrence
        first_ciesta = path_str.find("ciesta-assistant")
        base_path = path_str[:first_ciesta + len("ciesta-assistant")]
        project_root = Path(base_path)
        if project_root.exists() and (project_root / "requirements.txt").exists():
            print_info(f"S·ª≠ d·ª•ng th∆∞ m·ª•c ngo√†i c√πng: {project_root}")
            os.chdir(project_root)
        else:
            # Try to find in /content
            content_ciesta = Path("/content/ciesta-assistant")
            if content_ciesta.exists() and (content_ciesta / "requirements.txt").exists():
                project_root = content_ciesta
                print_info(f"S·ª≠ d·ª•ng: {project_root}")
                os.chdir(project_root)
    else:
        project_root = find_project_root()
        if project_root:
            print_info(f"T√¨m th·∫•y project t·∫°i: {project_root}")
            os.chdir(project_root)
            print_info(f"ƒê√£ chuy·ªÉn v√†o th∆∞ m·ª•c: {Path.cwd()}")
        else:
            print_warning("Kh√¥ng t√¨m th·∫•y project root, s·ª≠ d·ª•ng th∆∞ m·ª•c hi·ªán t·∫°i")
            project_root = Path.cwd()
    
    # Initialize python_cmd - will be used throughout the function
    python_cmd = None
    
    # Check if Colab
    if is_colab():
        print_info("Ph√°t hi·ªán Google Colab environment")
        
        # Install system dependencies
        print_info("C√†i ƒë·∫∑t system dependencies...")
        subprocess.run(["apt-get", "update", "-qq"], check=False)
        subprocess.run(["apt-get", "install", "-qq", "-y", "git", "software-properties-common"], check=False)
        
        # Determine which Python to use
        # After cloning new repo, sys.executable might point to non-existent venv
        # So we need to check if it exists, otherwise use system Python
        if sys.executable and Path(sys.executable).exists():
            python_cmd = sys.executable
            print_info(f"S·ª≠ d·ª•ng Python t·ª´ sys.executable: {python_cmd}")
        else:
            # Try to find system Python
            for py_cmd in ["python3", "python"]:
                try:
                    result = subprocess.run(["which", py_cmd], capture_output=True, text=True, check=False)
                    if result.returncode == 0 and result.stdout.strip():
                        python_cmd = result.stdout.strip()
                        print_info(f"S·ª≠ d·ª•ng system Python: {python_cmd}")
                        break
                except Exception:
                    continue
            
            if not python_cmd:
                # Fallback to sys.executable (even if path doesn't exist, it might work)
                python_cmd = sys.executable
                print_warning(f"S·ª≠ d·ª•ng sys.executable (c√≥ th·ªÉ kh√¥ng t·ªìn t·∫°i): {python_cmd}")
        
        # Upgrade pip
        print_info("Upgrade pip...")
        try:
            subprocess.run([python_cmd, "-m", "pip", "install", "--upgrade", "pip", "setuptools", "wheel"], 
                         check=False, timeout=300)
        except Exception as e:
            print_warning(f"Kh√¥ng th·ªÉ upgrade pip v·ªõi {python_cmd}: {e}")
            # Try with python3 directly
            try:
                subprocess.run(["python3", "-m", "pip", "install", "--upgrade", "pip", "setuptools", "wheel"], 
                             check=False, timeout=300)
                python_cmd = "python3"
            except Exception as e2:
                print_error(f"Kh√¥ng th·ªÉ upgrade pip: {e2}")
    else:
        # Not Colab - use sys.executable
        python_cmd = sys.executable
    
    # Check if we need to install Python 3.10 (only on Colab)
    if is_colab() and not python_ok:
        print_warning("C·∫ßn Python 3.10 ƒë·ªÉ ch·∫°y Rasa 3.6.20")
        print_info("ƒêang c√†i ƒë·∫∑t Python 3.10 tr√™n Colab...")
        
        # Install Python 3.10
        try:
            # Install Python 3.10 from apt
            print_info("ƒêang c√†i ƒë·∫∑t Python 3.10 v√† c√°c package c·∫ßn thi·∫øt...")
            subprocess.run([
                "apt-get", "install", "-y", "-qq",
                "python3.10", "python3.10-venv", "python3.10-dev"
            ], check=False)
            
            # Create virtual environment with Python 3.10
            print_info("ƒêang t·∫°o virtual environment v·ªõi Python 3.10...")
            venv_path = Path("venv_py310")
            
            # Remove old venv if exists
            if venv_path.exists():
                shutil.rmtree(venv_path)
            
            # Create new venv
            result = subprocess.run([
                "python3.10", "-m", "venv", str(venv_path)
            ], check=False, capture_output=True, text=True)
            
            if result.returncode == 0:
                # Get Python path from venv
                python310_path = venv_path / "bin" / "python"
                
                if python310_path.exists():
                    print_success(f"ƒê√£ t·∫°o virtual environment v·ªõi Python 3.10 t·∫°i: {python310_path}")
                    sys.executable = str(python310_path)
                    # Update python_cmd for subsequent operations
                    python_cmd = str(python310_path)
                    # Update PATH to include venv
                    venv_bin = str(venv_path / "bin")
                    os.environ["PATH"] = venv_bin + ":" + os.environ.get("PATH", "")
                    python_ok = True
                    
                    # Upgrade pip in the new venv
                    print_info("Upgrade pip trong venv m·ªõi...")
                    subprocess.run([python_cmd, "-m", "pip", "install", "--upgrade", "pip", "setuptools", "wheel"], 
                                 check=False, timeout=300)
                else:
                    raise Exception("Kh√¥ng t√¨m th·∫•y Python trong venv")
            else:
                raise Exception(f"Kh√¥ng th·ªÉ t·∫°o venv: {result.stderr}")
                
        except Exception as e:
            print_warning(f"Kh√¥ng th·ªÉ c√†i Python 3.10: {e}")
            print_info("S·∫Ω s·ª≠ d·ª•ng Python 3.12 v·ªõi Rasa version m·ªõi h∆°n...")
            print_info("üí° L∆∞u √Ω: M·ªôt s·ªë t√≠nh nƒÉng c√≥ th·ªÉ kh√¥ng ho·∫°t ƒë·ªông v·ªõi Python 3.12")
            # Ensure python_cmd is set even if venv creation failed
            if not python_cmd:
                python_cmd = "python3"
    
    # Find requirements file
    requirements_file = None
    possible_locations = [
        Path("requirements-colab.txt"),
        Path("requirements.txt"),
        Path("../requirements-colab.txt"),
        Path("../requirements.txt"),
        Path("ciesta-assistant/requirements-colab.txt"),
        Path("ciesta-assistant/requirements.txt"),
    ]
    
    # Try to find requirements file
    original_requirements_file = None
    for req_path in possible_locations:
        if req_path.exists():
            original_requirements_file = req_path.resolve()
            print_info(f"T√¨m th·∫•y {req_path.name} t·∫°i: {original_requirements_file}")
            break
    
    # Fix requirements file for compatibility (for Python 3.10 with Rasa 3.6.20)
    if python_ok and original_requirements_file:
        # Rasa 3.6.20 requires regex<2022.11, but requirements-colab.txt might have newer version
        # Create a fixed requirements file
        print_info("ƒêang ki·ªÉm tra v√† s·ª≠a conflicts trong requirements file...")
        temp_requirements = Path("requirements-colab-fixed.txt")
        try:
            # Read original requirements
            with open(original_requirements_file, 'r') as f:
                original_req = f.read()
            
            updated_req = original_req
            
            # Fix regex version conflict: Rasa 3.6.20 requires regex<2022.11
            # Replace any regex version >= 2022.11 with compatible version
            regex_patterns = [
                r'regex\s*==\s*(\d{4})\.(\d+)\.(\d+)',  # regex==2024.5.15
                r'regex\s*==\s*(\d{4})\.(\d+)',  # regex==2024.5
                r'regex\s*>=\s*(\d{4})',  # regex>=2024
            ]
            
            regex_found = False
            for pattern in regex_patterns:
                regex_match = re.search(pattern, updated_req)
                if regex_match:
                    regex_found = True
                    # Extract year and month if available
                    year = int(regex_match.group(1))
                    month = int(regex_match.group(2)) if len(regex_match.groups()) >= 2 else 0
                    
                    # Check if version is incompatible (year > 2022 or year == 2022 and month >= 11)
                    if year > 2022 or (year == 2022 and month >= 11):
                        # Replace with last compatible version: regex==2022.9.13
                        updated_req = re.sub(
                            r'regex\s*==\s*[\d.]+',
                            'regex==2022.9.13  # Fixed: Rasa 3.6.20 requires regex<2022.11',
                            updated_req
                        )
                        # Also replace >= patterns
                        updated_req = re.sub(
                            r'regex\s*>=\s*[\d.]+',
                            'regex==2022.9.13  # Fixed: Rasa 3.6.20 requires regex<2022.11',
                            updated_req
                        )
                        print_success("   ‚úÖ ƒê√£ s·ª≠a regex version ƒë·ªÉ t∆∞∆°ng th√≠ch v·ªõi Rasa 3.6.20")
                        print_info("      regex==2024.5.15 -> regex==2022.9.13")
                        break
            
            # If no regex found, add it with compatible version
            if not regex_found and 'rasa' in updated_req.lower():
                # Add regex with compatible version
                updated_req += "\n# Text preprocessing for Vietnamese - Fixed for Rasa 3.6.20 compatibility\nregex==2022.9.13\n"
                print_info("   ‚úÖ ƒê√£ th√™m regex version t∆∞∆°ng th√≠ch")
            
            # Also ensure numpy version is compatible
            if 'numpy' in updated_req:
                # Rasa 3.6.20 works with numpy 1.23.5 or 1.24.x (but not 2.x)
                updated_req = re.sub(
                    r'numpy\s*==\s*2\.\d+',
                    'numpy==1.26.4  # Fixed: Rasa 3.6.20 requires numpy<2.0',
                    updated_req
                )
            
            # Write fixed requirements file
            with open(temp_requirements, 'w') as f:
                f.write(updated_req)
            
            requirements_file = temp_requirements
            print_info(f"‚úÖ ƒê√£ t·∫°o requirements file ƒë√£ s·ª≠a: {temp_requirements}")
            print_info("üí° File n√†y ƒë√£ ƒë∆∞·ª£c ƒëi·ªÅu ch·ªânh ƒë·ªÉ t∆∞∆°ng th√≠ch v·ªõi Rasa 3.6.20")
            
        except Exception as e:
            print_warning(f"Kh√¥ng th·ªÉ t·∫°o requirements file ƒë√£ s·ª≠a: {e}")
            print_info("S·∫Ω s·ª≠ d·ª•ng requirements file g·ªëc...")
            requirements_file = original_requirements_file
    elif not python_ok and is_colab():
        # Python 3.12 - create requirements with newer Rasa version
        if original_requirements_file:
            print_warning("Python 3.12 kh√¥ng t∆∞∆°ng th√≠ch v·ªõi Rasa 3.6.20")
            print_info("T·∫°o requirements file t·∫°m th·ªùi v·ªõi Rasa version m·ªõi h∆°n (>=3.7.0)...")
            
            temp_requirements = Path("requirements-colab-py312.txt")
            try:
                with open(original_requirements_file, 'r') as f:
                    original_req = f.read()
                
                # Replace Rasa version with newer one that supports Python 3.12
                updated_req = re.sub(
                    r'rasa==[\d.]+',
                    'rasa>=3.7.0',
                    original_req
                )
                updated_req = re.sub(
                    r'rasa-sdk==[\d.]+',
                    'rasa-sdk>=3.7.0',
                    updated_req
                )
                
                # Update numpy to a version compatible with Python 3.12
                updated_req = re.sub(
                    r'numpy\s*==\s*1\.23\.5',
                    'numpy>=1.24.0',
                    updated_req
                )
                
                with open(temp_requirements, 'w') as f:
                    f.write(updated_req)
                
                requirements_file = temp_requirements
                print_info(f"‚úÖ ƒê√£ t·∫°o requirements file t·∫°m th·ªùi: {temp_requirements}")
                print_info("üí° File n√†y s·ª≠ d·ª•ng Rasa >=3.7.0 (h·ªó tr·ª£ Python 3.12)")
            except Exception as e:
                print_error(f"Kh√¥ng th·ªÉ t·∫°o requirements file t·∫°m th·ªùi: {e}")
                print_warning("S·∫Ω s·ª≠ d·ª•ng requirements file g·ªëc - c√≥ th·ªÉ g·∫∑p l·ªói v·ªõi Python 3.12")
                requirements_file = original_requirements_file
        else:
            print_error("Kh√¥ng t√¨m th·∫•y requirements.txt v√† Python 3.12 kh√¥ng t∆∞∆°ng th√≠ch")
            print_info("Vui l√≤ng c√†i Python 3.10 ho·∫∑c t·∫°o requirements.txt")
            return False
    else:
        # Python is OK or not Colab, use original requirements file
        requirements_file = original_requirements_file
    
    if not requirements_file:
        print_error("Kh√¥ng t√¨m th·∫•y requirements.txt ho·∫∑c requirements-colab.txt")
        print_info("ƒêang t√¨m trong c√°c th∆∞ m·ª•c:")
        for loc in possible_locations:
            exists = loc.exists()
            print_info(f"  - {loc} ({'t·ªìn t·∫°i' if exists else 'kh√¥ng t·ªìn t·∫°i'})")
        return False
    
    if not requirements_file.exists():
        print_error(f"Requirements file kh√¥ng t·ªìn t·∫°i: {requirements_file}")
        return False
    
    # Install packages
    print_info(f"C√†i ƒë·∫∑t t·ª´: {requirements_file}")
    print_info(f"   ƒê∆∞·ªùng d·∫´n ƒë·∫ßy ƒë·ªß: {requirements_file.resolve()}")
    print_info("‚è≥ Qu√° tr√¨nh n√†y c√≥ th·ªÉ m·∫•t 10-20 ph√∫t, KH√îNG interrupt!")
    print_warning("‚ö†Ô∏è QUAN TR·ªåNG: Qu√° tr√¨nh n√†y c√≥ th·ªÉ m·∫•t 10-20 ph√∫t, KH√îNG interrupt!")
    print_info("   ƒê·ªÉ c√†i ƒë·∫∑t ch·∫°y ƒë·∫øn khi ho√†n t·∫•t...")
    
    # Verify requirements file exists and is readable
    if not requirements_file.exists():
        print_error(f"Requirements file kh√¥ng t·ªìn t·∫°i: {requirements_file}")
        return False
    
    # Check file size
    file_size = requirements_file.stat().st_size
    if file_size == 0:
        print_error(f"Requirements file r·ªóng: {requirements_file}")
        return False
    
    print_info(f"   K√≠ch th∆∞·ªõc file: {file_size} bytes")
    
    # Ensure python_cmd is set (fallback to sys.executable if not set)
    if not python_cmd:
        python_cmd = sys.executable
    
    # Upgrade pip first
    print_info("ƒêang upgrade pip...")
    pip_upgrade_result = subprocess.run(
        [python_cmd, "-m", "pip", "install", "--upgrade", "pip", "setuptools", "wheel"],
        check=False,
        capture_output=True,
        text=True
    )
    
    if pip_upgrade_result.returncode != 0:
        print_warning("C√≥ l·ªói khi upgrade pip, nh∆∞ng s·∫Ω ti·∫øp t·ª•c...")
        if pip_upgrade_result.stderr:
            print_warning(f"  {pip_upgrade_result.stderr[:200]}")
    else:
        print_success("ƒê√£ upgrade pip th√†nh c√¥ng")
    
    try:
        # Run pip install with real-time output
        print_info(f"ƒêang c√†i ƒë·∫∑t packages t·ª´ {requirements_file.name}...")
        print_info("   (Qu√° tr√¨nh n√†y c√≥ th·ªÉ m·∫•t 10-20 ph√∫t, vui l√≤ng ƒë·ª£i...)")
        
        # Run pip install with output captured for error analysis
        pip_process = subprocess.run(
            [python_cmd, "-m", "pip", "install", "-r", str(requirements_file)],
            capture_output=True,  # Capture output ƒë·ªÉ ph√¢n t√≠ch l·ªói
            text=True,
            check=False,
            timeout=1800  # 30 ph√∫t timeout
        )
        
        # Print output
        if pip_process.stdout:
            print(pip_process.stdout)
        if pip_process.stderr:
            print(pip_process.stderr)
        
        if pip_process.returncode != 0:
            print_error("L·ªói khi c√†i ƒë·∫∑t dependencies!")
            print_info("Chi ti·∫øt l·ªói:")
            if pip_process.stderr:
                print_error(pip_process.stderr)
            if pip_process.stdout:
                # T√¨m d√≤ng l·ªói trong output
                for line in pip_process.stdout.split('\n'):
                    if 'error' in line.lower() or 'failed' in line.lower() or 'ERROR' in line:
                        print_error(f"  {line}")
            
            print_warning("Vui l√≤ng ch·∫°y l·∫°i script t·ª´ ƒë·∫ßu")
            print_warning(f"Ho·∫∑c c√†i ƒë·∫∑t th·ªß c√¥ng: {python_cmd} -m pip install -r {requirements_file}")
            
            # Th·ª≠ c√†i ƒë·∫∑t t·ª´ng package ƒë·ªÉ t√¨m package l·ªói
            print_info("ƒêang th·ª≠ c√†i ƒë·∫∑t t·ª´ng package ƒë·ªÉ t√¨m l·ªói...")
            try:
                with open(requirements_file, 'r') as f:
                    lines = f.readlines()
                
                failed_packages = []
                for line in lines:
                    line = line.strip()
                    if line and not line.startswith('#'):
                        package = line.split('==')[0].split('>=')[0].split('<=')[0].strip()
                        if package:
                            print_info(f"ƒêang th·ª≠ c√†i: {package}...")
                            result = subprocess.run(
                                [python_cmd, "-m", "pip", "install", line],
                                capture_output=True,
                                text=True,
                                timeout=300
                            )
                            if result.returncode == 0:
                                print_success(f"  ‚úì {package}")
                            else:
                                print_error(f"  ‚úó {package} - L·ªói")
                                if result.stderr:
                                    print_error(f"    {result.stderr[:200]}")
                                failed_packages.append(package)
            except Exception as e:
                print_warning(f"Kh√¥ng th·ªÉ ph√¢n t√≠ch l·ªói chi ti·∫øt: {e}")
            
            return False
        
        print_success("ƒê√£ c√†i ƒë·∫∑t dependencies th√†nh c√¥ng!")
        
        # Ki·ªÉm tra c√°c packages quan tr·ªçng
        print_info("Ki·ªÉm tra packages quan tr·ªçng...")
        check_packages_script = """
import sys
import os
venv_path = os.path.join(os.getcwd(), 'venv_py310', 'lib', 'python3.10', 'site-packages')
if os.path.exists(venv_path):
    sys.path.insert(0, venv_path)
packages = ['rasa', 'torch', 'transformers']
missing = []
for pkg in packages:
    try:
        __import__(pkg)
        print(f"‚úÖ {pkg}")
    except ImportError:
        print(f"‚ùå {pkg} - CH∆ØA C√ÄI ƒê·∫∂T")
        missing.append(pkg)

if missing:
    sys.exit(1)
"""
        check_file = Path("/tmp/check_packages.py")
        with open(check_file, "w") as f:
            f.write(check_packages_script)
        
        # python_cmd should already be set, but ensure it's set just in case
        if not python_cmd:
            python_cmd = sys.executable
        
        result = subprocess.run(
            [python_cmd, str(check_file)],
            capture_output=True,
            text=True,
            cwd=str(Path.cwd())
        )
        
        if result.returncode != 0:
            print(result.stdout)
            print_error("M·ªôt s·ªë packages quan tr·ªçng ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t!")
            print_warning("‚ö†Ô∏è Vui l√≤ng ch·∫°y l·∫°i script t·ª´ ƒë·∫ßu v√† ƒë·ª£i c√†i ƒë·∫∑t ho√†n t·∫•t")
            print_warning("‚ö†Ô∏è KH√îNG interrupt qu√° tr√¨nh c√†i ƒë·∫∑t (c√≥ th·ªÉ m·∫•t 10-20 ph√∫t)")
            return False
        else:
            print(result.stdout)
            print_success("T·∫•t c·∫£ packages quan tr·ªçng ƒë√£ ƒë∆∞·ª£c c√†i ƒë·∫∑t")
        
        return True
        
    except Exception as e:
        print_error(f"L·ªói kh√¥ng mong ƒë·ª£i khi c√†i ƒë·∫∑t: {e}")
        import traceback
        traceback.print_exc()
        return False

def setup_project_structure():
    """Setup project structure"""
    print_header("THI·∫æT L·∫¨P C·∫§U TR√öC PROJECT")
    
    # Ensure we're in project root
    project_root = find_project_root()
    if project_root and project_root != Path.cwd():
        os.chdir(project_root)
        print_info(f"ƒê√£ chuy·ªÉn v√†o project root: {Path.cwd()}")
    
    # Create necessary directories
    directories = [
        "models",
        "models_hub",
        "models_hub/phobert-large",
        "custom_components",
        "data",
        "data/knowledge_base",
        "data/knowledge_base/provinces",
        "actions"
    ]
    
    for dir_path in directories:
        Path(dir_path).mkdir(parents=True, exist_ok=True)
        print_success(f"ƒê√£ t·∫°o/th∆∞ m·ª•c: {dir_path}")
    
    return True

def download_phobert_model(model_name: str = "vinai/phobert-large", 
                          local_dir: str = "models_hub/phobert-large"):
    """Download PhoBERT model from HuggingFace"""
    print_header("T·∫¢I PHOBERT-LARGE MODEL")
    
    local_path = Path(local_dir)
    
    # Check if model already exists
    config_file = local_path / "config.json"
    if config_file.exists():
        print_success(f"Model ƒë√£ t·ªìn t·∫°i t·∫°i {local_dir}")
        return True
    
    print_info(f"ƒêang t·∫£i model {model_name} t·ª´ HuggingFace...")
    print_warning("Qu√° tr√¨nh n√†y c√≥ th·ªÉ m·∫•t 5-10 ph√∫t t√πy v√†o t·ªëc ƒë·ªô m·∫°ng")
    
    try:
        from huggingface_hub import snapshot_download
        
        snapshot_download(
            repo_id=model_name,
            local_dir=str(local_path),
            local_dir_use_symlinks=False,
            resume_download=True
        )
        
        print_success(f"ƒê√£ t·∫£i model th√†nh c√¥ng v√†o {local_dir}")
        return True
        
    except Exception as e:
        print_error(f"L·ªói khi t·∫£i model: {e}")
        return False

def cleanup_and_clone_repo(git_url: str = "https://github.com/HoangPhucDE/ciesta-assistant.git", 
                           branch: str = "main",
                           target_dir: str = "ciesta-assistant"):
    """
    Cleanup old repo and clone fresh from git (Colab only)
    
    Args:
        git_url: Git repository URL
        branch: Branch to clone (default: main)
        target_dir: Target directory name
    """
    if not is_colab():
        print_info("Kh√¥ng ph·∫£i Colab - b·ªè qua cleanup v√† clone")
        return False
    
    # Check if git is available
    git_check = subprocess.run(["which", "git"], capture_output=True, text=True)
    if git_check.returncode != 0:
        print_warning("Git ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t, ƒëang c√†i ƒë·∫∑t...")
        subprocess.run(["apt-get", "update", "-qq"], check=False)
        subprocess.run(["apt-get", "install", "-y", "-qq", "git"], check=False)
        print_success("ƒê√£ c√†i ƒë·∫∑t git")
    
    print_header("CLEANUP V√Ä CLONE REPO M·ªöI")
    
    current_dir = Path.cwd()
    target_path = current_dir / target_dir
    
    # Step 1: Remove old directory if exists
    if target_path.exists():
        print_info(f"ƒêang x√≥a th∆∞ m·ª•c c≈©: {target_path}")
        try:
            shutil.rmtree(target_path)
            print_success(f"ƒê√£ x√≥a th∆∞ m·ª•c c≈©: {target_path}")
        except Exception as e:
            print_error(f"Kh√¥ng th·ªÉ x√≥a th∆∞ m·ª•c c≈©: {e}")
            print_warning("S·∫Ω th·ª≠ clone v√†o th∆∞ m·ª•c kh√°c...")
            target_path = current_dir / f"{target_dir}-new"
            if target_path.exists():
                try:
                    shutil.rmtree(target_path)
                except Exception:
                    pass
    
    # Step 2: Clone fresh repo
    print_info(f"ƒêang clone repo t·ª´: {git_url}")
    print_info(f"   Branch: {branch}")
    print_info(f"   Target: {target_path}")
    print_warning("‚ö†Ô∏è Qu√° tr√¨nh n√†y c√≥ th·ªÉ m·∫•t 1-2 ph√∫t...")
    
    try:
        # Clone repository v·ªõi shallow clone (ch·ªâ l·∫•y commit m·ªõi nh·∫•t)
        clone_cmd = ["git", "clone", "--depth", "1", "--branch", branch, git_url, str(target_path)]
        result = subprocess.run(
            clone_cmd,
            capture_output=True,
            text=True,
            timeout=300  # 5 minutes timeout
        )
        
        if result.returncode != 0:
            print_warning(f"Kh√¥ng th·ªÉ clone branch {branch}: {result.stderr}")
            # Try without branch specification (clone default branch)
            print_info("Th·ª≠ clone branch m·∫∑c ƒë·ªãnh...")
            clone_cmd = ["git", "clone", "--depth", "1", git_url, str(target_path)]
            result = subprocess.run(
                clone_cmd,
                capture_output=True,
                text=True,
                timeout=300
            )
            if result.returncode != 0:
                print_error(f"L·ªói khi clone repo: {result.stderr}")
                if result.stdout:
                    print_error(f"Output: {result.stdout}")
                return False
            else:
                print_info("ƒê√£ clone branch m·∫∑c ƒë·ªãnh th√†nh c√¥ng")
        else:
            print_success(f"ƒê√£ clone branch {branch} th√†nh c√¥ng")
        
        print_success(f"ƒê√£ clone repo th√†nh c√¥ng v√†o: {target_path}")
        
        # Step 3: Change to cloned directory
        if target_path.exists():
            # Check if it's a valid repo
            if (target_path / "requirements.txt").exists() or (target_path / "requirements-colab.txt").exists():
                os.chdir(target_path)
                print_success(f"ƒê√£ chuy·ªÉn v√†o th∆∞ m·ª•c: {Path.cwd()}")
                return True
            else:
                # Maybe it's a nested directory
                nested_paths = [
                    target_path / "ciesta-assistant",
                    target_path / "ciesta-asisstant",  # Typo variant
                ]
                for nested_path in nested_paths:
                    if nested_path.exists() and ((nested_path / "requirements.txt").exists() or (nested_path / "requirements-colab.txt").exists()):
                        os.chdir(nested_path)
                        print_success(f"ƒê√£ chuy·ªÉn v√†o th∆∞ m·ª•c: {Path.cwd()}")
                        return True
                
                print_error(f"Th∆∞ m·ª•c clone kh√¥ng h·ª£p l·ªá (kh√¥ng t√¨m th·∫•y requirements.txt): {target_path}")
                print_info(f"C√°c file trong th∆∞ m·ª•c: {list(target_path.iterdir())[:10]}")
                return False
        else:
            print_error(f"Th∆∞ m·ª•c clone kh√¥ng t·ªìn t·∫°i: {target_path}")
            return False
            
    except subprocess.TimeoutExpired:
        print_error("Timeout khi clone repo (qu√° 5 ph√∫t)")
        return False
    except Exception as e:
        print_error(f"L·ªói kh√¥ng mong ƒë·ª£i khi clone: {e}")
        import traceback
        traceback.print_exc()
        return False

def setup_custom_components():
    """Setup custom components"""
    print_header("THI·∫æT L·∫¨P CUSTOM COMPONENTS")
    
    # Ensure we're in project root
    project_root = find_project_root()
    if project_root and project_root != Path.cwd():
        os.chdir(project_root)
    
    # Check if custom components exist
    phobert_featurizer = Path("custom_components/phobert_featurizer.py")
    if not phobert_featurizer.exists():
        # Try alternative paths
        alt_paths = [
            Path("custom_components/phobert_featurizer.py"),
            Path("../custom_components/phobert_featurizer.py"),
            Path("ciesta-assistant/custom_components/phobert_featurizer.py"),
        ]
        
        found = False
        for alt_path in alt_paths:
            if alt_path.exists():
                print_info(f"T√¨m th·∫•y t·∫°i: {alt_path}")
                found = True
                break
        
        if not found:
            print_error("Kh√¥ng t√¨m th·∫•y custom_components/phobert_featurizer.py")
            print_info("Vui l√≤ng ƒë·∫£m b·∫£o ƒë√£ clone repo v√† chuy·ªÉn v√†o th∆∞ m·ª•c ciesta-assistant")
            return False
    
    print_success("Custom components ƒë√£ s·∫µn s√†ng")
    return True

def create_symlink():
    """Create symlink from models/phobert-large to models_hub/phobert-large"""
    print_header("T·∫†O SYMLINK CHO MODEL")
    
    source = Path("models_hub/phobert-large")
    target = Path("models/phobert-large")
    
    if not source.exists():
        print_error(f"Kh√¥ng t√¨m th·∫•y {source}")
        return False
    
    # Remove existing symlink or directory
    if target.exists():
        if target.is_symlink():
            target.unlink()
        else:
            shutil.rmtree(target)
    
    # Create symlink
    try:
        target.symlink_to(source.relative_to(target.parent))
        print_success(f"ƒê√£ t·∫°o symlink: {target} -> {source}")
        return True
    except Exception as e:
        # On Windows or if symlink fails, copy directory
        print_warning(f"Kh√¥ng th·ªÉ t·∫°o symlink: {e}")
        print_info("ƒêang copy th∆∞ m·ª•c...")
        shutil.copytree(source, target)
        print_success(f"ƒê√£ copy model v√†o {target}")
        return True

def get_gpu_info():
    """Get GPU information including name and memory"""
    # First check with nvidia-smi
    nvidia_result = None
    try:
        nvidia_result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)
        if nvidia_result.returncode != 0:
            return {'available': False, 'name': None, 'memory_gb': 0}
    except Exception:
        return {'available': False, 'name': None, 'memory_gb': 0}
    
    # Then check with PyTorch (from venv if available)
    try:
        # Try to import torch from venv
        venv_path = Path("venv_py310")
        if venv_path.exists():
            venv_site_packages = venv_path / "lib" / "python3.10" / "site-packages"
            if venv_site_packages.exists():
                import sys
                sys.path.insert(0, str(venv_site_packages))
        
        import torch
        if torch.cuda.is_available():
            gpu_name = torch.cuda.get_device_name(0)
            gpu_memory_bytes = torch.cuda.get_device_properties(0).total_memory
            gpu_memory_gb = gpu_memory_bytes / (1024**3)
            return {
                'name': gpu_name,
                'memory_gb': gpu_memory_gb,
                'available': True
            }
    except Exception:
        # If torch not available, still return True if nvidia-smi works
        if nvidia_result and nvidia_result.returncode == 0:
            return {'available': True, 'name': 'GPU (detected by nvidia-smi)', 'memory_gb': 0}
        pass
    
    return {'available': False, 'name': None, 'memory_gb': 0}

def optimize_config_for_gpu(config_file: Path, gpu_info: dict):
    """Optimize config.yml for maximum speed on GPU while avoiding OOM"""
    # Get GPU memory from PyTorch
    gpu_memory_gb = None
    gpu_name = None
    
    try:
        # Try to import torch from venv
        venv_path = Path("venv_py310")
        if venv_path.exists():
            venv_site_packages = venv_path / "lib" / "python3.10" / "site-packages"
            if venv_site_packages.exists():
                import sys
                sys.path.insert(0, str(venv_site_packages))
        
        check_gpu_memory_script = """
import sys
import os
venv_path = os.path.join(os.getcwd(), 'venv_py310', 'lib', 'python3.10', 'site-packages')
if os.path.exists(venv_path):
    sys.path.insert(0, venv_path)

try:
    import torch
    if torch.cuda.is_available():
        gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)
        gpu_name = torch.cuda.get_device_name(0)
        print(f"{gpu_memory:.1f}|{gpu_name}")
    else:
        print("0|No GPU")
except ImportError as e:
    print(f"0|PyTorch not installed: {e}")
except Exception as e:
    print(f"0|Error: {e}")
"""
        check_file = Path("/tmp/check_gpu_memory.py")
        with open(check_file, "w") as f:
            f.write(check_gpu_memory_script)
        
        result = subprocess.run(
            [sys.executable, str(check_file)],
            capture_output=True,
            text=True,
            cwd=str(Path.cwd()),
            timeout=30
        )
        
        if result.returncode == 0 and result.stdout.strip():
            output = result.stdout.strip()
            if "|" in output:
                parts = output.split("|")
                gpu_memory_gb = float(parts[0])
                gpu_name = parts[1] if len(parts) > 1 else "Unknown"
    except Exception as e:
        print_warning(f"Kh√¥ng th·ªÉ ki·ªÉm tra GPU memory: {e}")
    
    if not gpu_info['available'] or (gpu_memory_gb and gpu_memory_gb == 0):
        print_warning("Kh√¥ng c√≥ GPU - Gi·ªØ c·∫•u h√¨nh m·∫∑c ƒë·ªãnh")
        return False
    
    if gpu_memory_gb:
        print_info(f"GPU: {gpu_name} ({gpu_memory_gb:.1f} GB)")
    else:
        print_info(f"GPU: {gpu_info.get('name', 'Unknown')}")
        gpu_memory_gb = 0  # Fallback
    
    # Read config
    with open(config_file, "r", encoding="utf-8") as f:
        config_content = f.read()
    
    original_content = config_content
    optimized = False
    
    # T·ªëi ∆∞u batch size d·ª±a tr√™n GPU memory
    # L∆∞u √Ω: T4 th∆∞·ªùng c√≥ ~15GB nh∆∞ng c√≥ th·ªÉ hi·ªÉn th·ªã 14.7-14.9 GB, n√™n coi >=14.5 GB l√† GPU l·ªõn
    if gpu_memory_gb >= 14.5:  # T4 (~15GB), V100, A100
        print_success(f"üöÄ GPU l·ªõn ph√°t hi·ªán ({gpu_name}) - TƒÉng batch size ƒë·ªÉ t·∫≠n d·ª•ng GPU")
        print_info(f"   üí° GPU Memory: {gpu_memory_gb:.1f} GB - C√≥ th·ªÉ tƒÉng batch size cao h∆°n")
        
        # T·ªëi ∆∞u PhoBERTFeaturizer batch_size (sau pooling_strategy)
        # Ultra optimization: V·ªõi T4 15GB, tƒÉng l√™n 256 ƒë·ªÉ s·ª≠ d·ª•ng 80%+ GPU memory
        phobert_batch = 256
        config_content = re.sub(
            r'(pooling_strategy:\s*"mean_max"\s*\n\s*batch_size:)\s*\d+(\s*#.*)?',
            rf'\1 {phobert_batch}  # Ultra optimization cho GPU l·ªõn (T4/V100/A100) - t·∫≠n d·ª•ng t·ªëi ƒëa GPU memory',
            config_content
        )
        print_success(f"   ‚úÖ PhoBERTFeaturizer batch_size: {phobert_batch}")
        
        # Ultra optimization: DIETClassifier batch_size - tƒÉng cao [192, 384] ƒë·ªÉ training nhanh h∆°n 2-3x
        # T4 15GB c√≥ th·ªÉ ch·ªãu ƒë∆∞·ª£c batch size n√†y
        diet_batch = [192, 384]
        config_content = re.sub(
            r'(batch_size:\s*)\[16,\s*32\](\s*#.*)?',
            rf'\1{diet_batch}  # Ultra optimization cho GPU l·ªõn - training nhanh h∆°n 2-3x',
            config_content
        )
        # N·∫øu c√≥ pattern kh√°c t·ª´ l·∫ßn t·ªëi ∆∞u tr∆∞·ªõc, c≈©ng c·∫≠p nh·∫≠t
        config_content = re.sub(
            r'(batch_size:\s*)\[64,\s*128\](\s*#.*)?',
            rf'\1{diet_batch}  # Ultra optimization cho GPU l·ªõn - training nhanh h∆°n 2-3x',
            config_content
        )
        config_content = re.sub(
            r'(batch_size:\s*)\[128,\s*256\](\s*#.*)?',
            rf'\1{diet_batch}  # Ultra optimization cho GPU l·ªõn - training nhanh h∆°n 2-3x',
            config_content
        )
        print_success(f"   ‚úÖ DIETClassifier batch_size: {diet_batch}")
        optimized = True
        
    elif gpu_memory_gb >= 8:  # P100, K80, ho·∫∑c GPU trung b√¨nh
        print_info(f"‚ö° GPU trung b√¨nh ph√°t hi·ªán ({gpu_name}) - TƒÉng batch size v·ª´a ph·∫£i")
        phobert_batch = 96
        config_content = re.sub(
            r'(pooling_strategy:\s*"mean_max"\s*\n\s*batch_size:)\s*\d+(\s*#.*)?',
            rf'\1 {phobert_batch}  # T·ªëi ∆∞u cho GPU trung b√¨nh',
            config_content
        )
        diet_batch = [64, 128]
        config_content = re.sub(
            r'(batch_size:\s*)\[16,\s*32\](\s*#.*)?',
            rf'\1{diet_batch}  # T·ªëi ∆∞u cho GPU trung b√¨nh',
            config_content
        )
        print_success(f"   ‚úÖ PhoBERTFeaturizer batch_size: {phobert_batch}")
        print_success(f"   ‚úÖ DIETClassifier batch_size: {diet_batch}")
        optimized = True
        
    elif gpu_memory_gb >= 4:  # GPU nh·ªè
        print_info(f"üìä GPU nh·ªè ph√°t hi·ªán ({gpu_name}) - TƒÉng batch size nh·∫π")
        phobert_batch = 48
        config_content = re.sub(
            r'(pooling_strategy:\s*"mean_max"\s*\n\s*batch_size:)\s*\d+(\s*#.*)?',
            rf'\1 {phobert_batch}  # T·ªëi ∆∞u cho GPU nh·ªè',
            config_content
        )
        diet_batch = [32, 64]
        config_content = re.sub(
            r'(batch_size:\s*)\[16,\s*32\]',
            rf'\1{diet_batch}  # T·ªëi ∆∞u cho GPU nh·ªè',
            config_content
        )
        print_success(f"   ‚úÖ PhoBERTFeaturizer batch_size: {phobert_batch}")
        print_success(f"   ‚úÖ DIETClassifier batch_size: {diet_batch}")
        optimized = True
    else:
        print_info("   ‚ÑπÔ∏è GPU memory nh·ªè - Gi·ªØ batch size m·∫∑c ƒë·ªãnh")
    
    # Ghi l·∫°i config n·∫øu c√≥ thay ƒë·ªïi
    if optimized and config_content != original_content:
        with open(config_file, "w", encoding="utf-8") as f:
            f.write(config_content)
        print_success("   ‚úÖ ƒê√£ t·ªëi ∆∞u batch size trong config.yml")
        print_info("   üí° Batch size l·ªõn h∆°n s·∫Ω:")
        print_info("      - S·ª≠ d·ª•ng GPU hi·ªáu qu·∫£ h∆°n")
        print_info("      - Training nhanh h∆°n (nhi·ªÅu samples/batch)")
        print_info("      - T·∫≠n d·ª•ng GPU memory t·ªët h∆°n")
        
        # C≈©ng c·∫≠p nh·∫≠t file g·ªëc trong config/rasa/ ƒë·ªÉ ƒë·ªìng b·ªô
        rasa_config_path = Path.cwd() / "config" / "rasa" / "config.yml"
        if rasa_config_path.exists():
            with open(rasa_config_path, "w", encoding="utf-8") as f:
                f.write(config_content)
            print_success("   ‚úÖ ƒê√£ c·∫≠p nh·∫≠t c·∫£ file g·ªëc trong config/rasa/")
        return True
    else:
        print_info("   ‚ÑπÔ∏è Config ƒë√£ t·ªëi ∆∞u ho·∫∑c kh√¥ng c·∫ßn thay ƒë·ªïi")
    
    return False

def ultra_optimize_for_gpu(config_file: Path = None):
    """
    Ultra optimize config for maximum GPU usage
    - Disable validation during training ƒë·ªÉ tƒÉng t·ªëc
    - ƒê·∫£m b·∫£o batch size ƒë√£ ƒë∆∞·ª£c set cao
    """
    print_header("ULTRA OPTIMIZATION FOR GPU")
    
    if config_file is None:
        config_file = Path("config.yml")
        if not config_file.exists():
            config_file = Path("config/rasa/config.yml")
    
    if not config_file.exists():
        print_warning("Kh√¥ng t√¨m th·∫•y config.yml ƒë·ªÉ ultra optimize")
        return False
    
    print_info("üöÄ Ultra optimization: Disable validation ƒë·ªÉ tƒÉng t·ªëc training")
    
    with open(config_file, 'r', encoding='utf-8') as f:
        config_content = f.read()
    
    original_content = config_content
    optimized = False
    
    # 1. Disable validation during training (ch·ªâ validate cu·ªëi c√πng)
    # T√¨m DIETClassifier v√† set evaluate_every_number_of_epochs: -1
    if re.search(r'evaluate_every_number_of_epochs:\s*\d+', config_content):
        config_content = re.sub(
            r'evaluate_every_number_of_epochs:\s*\d+',
            'evaluate_every_number_of_epochs: -1  # Disable validation during training ƒë·ªÉ tƒÉng t·ªëc',
            config_content
        )
        print_success("   ‚úÖ Disabled validation during training (evaluate_every_number_of_epochs: -1)")
        optimized = True
    
    # 2. ƒê·∫£m b·∫£o evaluate_on_number_of_examples: 0 (kh√¥ng validate trong training)
    if re.search(r'evaluate_on_number_of_examples:\s*\d+', config_content):
        config_content = re.sub(
            r'evaluate_on_number_of_examples:\s*\d+',
            'evaluate_on_number_of_examples: 0  # Disable validation ƒë·ªÉ tƒÉng t·ªëc',
            config_content
        )
        print_success("   ‚úÖ Disabled evaluation examples (evaluate_on_number_of_examples: 0)")
        optimized = True
    
    # 3. Ghi l·∫°i config n·∫øu c√≥ thay ƒë·ªïi
    if optimized and config_content != original_content:
        with open(config_file, "w", encoding="utf-8") as f:
            f.write(config_content)
        print_success("   ‚úÖ ƒê√£ ultra optimize config.yml")
        print_info("   üí° Validation ƒë√£ ƒë∆∞·ª£c disable - Training s·∫Ω nhanh h∆°n 2-3x")
        
        # C≈©ng c·∫≠p nh·∫≠t file g·ªëc trong config/rasa/ ƒë·ªÉ ƒë·ªìng b·ªô
        rasa_config_path = Path.cwd() / "config" / "rasa" / "config.yml"
        if rasa_config_path.exists() and rasa_config_path != config_file:
            with open(rasa_config_path, "w", encoding="utf-8") as f:
                f.write(config_content)
            print_success("   ‚úÖ ƒê√£ c·∫≠p nh·∫≠t c·∫£ file g·ªëc trong config/rasa/")
        return True
    else:
        print_info("   ‚ÑπÔ∏è Config ƒë√£ ƒë∆∞·ª£c ultra optimize ho·∫∑c kh√¥ng c·∫ßn thay ƒë·ªïi")
    
    return False


def verify_config():
    """Verify config.yml is correct"""
    print_header("KI·ªÇM TRA CONFIG")
    
    # Ensure we're in project root
    project_root = find_project_root()
    if project_root and project_root != Path.cwd():
        os.chdir(project_root)
    
    config_file = Path("config.yml")
    if not config_file.exists():
        print_error("Kh√¥ng t√¨m th·∫•y config.yml")
        print_info(f"Th∆∞ m·ª•c hi·ªán t·∫°i: {Path.cwd()}")
        return False
    
    # Read config
    with open(config_file, "r", encoding="utf-8") as f:
        config_content = f.read()
    
    # Check if using local model
    if "models/phobert-large" in config_content:
        print_success("Config ƒëang s·ª≠ d·ª•ng model local")
    else:
        print_warning("Config c√≥ th·ªÉ ch∆∞a ƒë∆∞·ª£c c·∫•u h√¨nh ƒë·ªÉ d√πng model local")
    
    return True

def parse_rasa_progress(line: str):
    """Parse Rasa training progress line"""
    # Pattern: Epochs: 10% 60/600 [02:46<27:40:43, 166.35s/it, t_loss=32.3, m_acc=0.228, i_acc=0.186, e_f1=0.0868]
    pattern = r'Epochs:\s*(\d+)%\s*(\d+)/(\d+)\s*\[([\d:]+)<([\d:]+),\s*([\d.]+)s/it(?:,\s*t_loss=([\d.]+))?(?:,\s*m_acc=([\d.]+))?(?:,\s*i_acc=([\d.]+))?(?:,\s*e_f1=([\d.]+))?\]'
    match = re.search(pattern, line)
    
    if match:
        return {
            'percent': int(match.group(1)),
            'current': int(match.group(2)),
            'total': int(match.group(3)),
            'elapsed': match.group(4),
            'remaining': match.group(5),
            'time_per_epoch': float(match.group(6)),
            't_loss': float(match.group(7)) if match.group(7) else None,
            'm_acc': float(match.group(8)) if match.group(8) else None,
            'i_acc': float(match.group(9)) if match.group(9) else None,
            'e_f1': float(match.group(10)) if match.group(10) else None,
        }
    return None

def format_time(seconds: float) -> str:
    """Format seconds to human readable time"""
    if seconds < 60:
        return f"{seconds:.1f}s"
    elif seconds < 3600:
        minutes = int(seconds // 60)
        secs = int(seconds % 60)
        return f"{minutes}m {secs}s"
    else:
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        return f"{hours}h {minutes}m"

def print_progress_bar(percent: int, width: int = 40):
    """Print progress bar"""
    filled = int(width * percent / 100)
    bar = '‚ñà' * filled + '‚ñë' * (width - filled)
    return f"[{bar}] {percent}%"

def train_nlu(epochs: Optional[int] = None):
    """Train NLU model with real-time progress display"""
    print_header("B·∫ÆT ƒê·∫¶U TRAIN NLU MODEL")
    
    # Ensure we're in project root
    project_root = find_project_root()
    if project_root and project_root != Path.cwd():
        os.chdir(project_root)
        print_info(f"ƒê√£ chuy·ªÉn v√†o project root: {Path.cwd()}")
    
    # Check GPU (get detailed info from venv)
    gpu_info = get_gpu_info()
    
    # Try to get more detailed GPU info from venv
    venv_path = Path("venv_py310")
    if venv_path.exists():
        venv_site_packages = venv_path / "lib" / "python3.10" / "site-packages"
        if venv_site_packages.exists():
            try:
                import sys
                sys.path.insert(0, str(venv_site_packages))
                import torch
                if torch.cuda.is_available():
                    gpu_name = torch.cuda.get_device_name(0)
                    gpu_memory_bytes = torch.cuda.get_device_properties(0).total_memory
                    gpu_memory_gb = gpu_memory_bytes / (1024**3)
                    gpu_info = {
                        'available': True,
                        'name': gpu_name,
                        'memory_gb': gpu_memory_gb
                    }
            except Exception:
                pass  # Use gpu_info from get_gpu_info()
    
    if gpu_info['available']:
        gpu_name = gpu_info.get('name', 'GPU')
        gpu_memory_gb = gpu_info.get('memory_gb', 0)
        if gpu_memory_gb > 0:
            print_success(f"GPU ƒë√£ s·∫µn s√†ng: {gpu_name} ({gpu_memory_gb:.1f} GB)")
        else:
            print_success(f"GPU ƒë√£ s·∫µn s√†ng: {gpu_name}")
    else:
        print_warning("Kh√¥ng c√≥ GPU - Training s·∫Ω ch·∫≠m h∆°n (c√≥ th·ªÉ m·∫•t 1-2 gi·ªù)")
    
    # Verify files exist
    required_files = [
        "config.yml",
        "data/nlu.yml",
        "custom_components/phobert_featurizer.py"
    ]
    
    print_info(f"Ki·ªÉm tra files trong: {Path.cwd()}")
    for file_path in required_files:
        file_check = Path(file_path)
        if not file_check.exists():
            print_error(f"Kh√¥ng t√¨m th·∫•y {file_path}")
            print_info(f"  ƒê∆∞·ªùng d·∫´n ƒë·∫ßy ƒë·ªß: {file_check.resolve()}")
            return False
        else:
            print_success(f"  ‚úì {file_path}")
    
    # Show expected training time based on GPU
    gpu_memory_gb = gpu_info.get('memory_gb', 0)
    if gpu_info['available']:
        if gpu_memory_gb >= 14.5:
            print_info("‚ö° Training v·ªõi GPU l·ªõn (T4/V100/A100) - ∆Ø·ªõc t√≠nh: 15-30 ph√∫t")
        elif gpu_memory_gb >= 8:
            print_info("‚ö° Training v·ªõi GPU trung b√¨nh - ∆Ø·ªõc t√≠nh: 30-60 ph√∫t")
        elif gpu_memory_gb > 0:
            print_info("‚ö° Training v·ªõi GPU nh·ªè - ∆Ø·ªõc t√≠nh: 45-90 ph√∫t")
        else:
            print_info("‚ö° Training v·ªõi GPU (memory unknown) - ∆Ø·ªõc t√≠nh: 30-60 ph√∫t")
    else:
        print_info("‚è≥ Training v·ªõi CPU - ∆Ø·ªõc t√≠nh: 1-2 gi·ªù")
    
    print()
    
    start_time = time.time()
    last_update_time = start_time
    last_epoch = 0
    total_epochs = None
    progress_data = None
    
    # Check Rasa ƒë√£ ƒë∆∞·ª£c c√†i ƒë·∫∑t tr∆∞·ªõc khi train
    print_info("Ki·ªÉm tra Rasa tr∆∞·ªõc khi train...")
    check_rasa_script = """
import sys
import os
venv_path = os.path.join(os.getcwd(), 'venv_py310', 'lib', 'python3.10', 'site-packages')
if os.path.exists(venv_path):
    sys.path.insert(0, venv_path)

try:
    import rasa
    print(f"‚úÖ Rasa version: {rasa.__version__}")
    sys.exit(0)
except ImportError as e:
    print(f"‚ùå Rasa ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t: {e}")
    sys.exit(1)
"""
    check_file = Path("/tmp/check_rasa.py")
    with open(check_file, "w") as f:
        f.write(check_rasa_script)
    
    rasa_check = subprocess.run(
        [sys.executable, str(check_file)],
        capture_output=True,
        text=True,
        cwd=str(Path.cwd())
    )
    
    print(rasa_check.stdout)
    if rasa_check.stderr:
        print(rasa_check.stderr)
    
    if rasa_check.returncode != 0:
        print_error("Rasa ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t!")
        print_warning("‚ö†Ô∏è Vui l√≤ng ch·∫°y l·∫°i script t·ª´ ƒë·∫ßu v√† ƒë·ª£i c√†i ƒë·∫∑t ho√†n t·∫•t")
        print_warning("‚ö†Ô∏è KH√îNG interrupt qu√° tr√¨nh c√†i ƒë·∫∑t dependencies (c√≥ th·ªÉ m·∫•t 10-20 ph√∫t)")
        return False
    
    print_success("Rasa ƒë√£ s·∫µn s√†ng - B·∫Øt ƒë·∫ßu training...")
    
    try:
        # Train NLU with real-time output (use config.yml from root)
        # ƒê·∫£m b·∫£o config.yml t·ªìn t·∫°i ·ªü root tr∆∞·ªõc khi train
        if not (Path.cwd() / "config.yml").exists():
            print_error("config.yml kh√¥ng t·ªìn t·∫°i ·ªü root! Kh√¥ng th·ªÉ train.")
            return False
        
        cmd = [sys.executable, "-m", "rasa", "train", "nlu", "--config", "config.yml"]
        if epochs:
            print_warning("Epochs ƒë∆∞·ª£c c·∫•u h√¨nh trong config.yml")
        
        # Start process with real-time output
        process = subprocess.Popen(
            cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            universal_newlines=True,
            bufsize=1,
            cwd=str(Path.cwd())
        )
        
        print(f"{Colors.OKCYAN}{'='*80}{Colors.ENDC}")
        print(f"{Colors.BOLD}{Colors.HEADER}üìä TI·∫æN ƒê·ªò TRAINING{Colors.ENDC}")
        print(f"{Colors.OKCYAN}{'='*80}{Colors.ENDC}\n")
        
        # Read output line by line
        for line in process.stdout:
            line = line.rstrip()
            
            # Parse progress line
            progress = parse_rasa_progress(line)
            if progress:
                progress_data = progress
                total_epochs = progress['total']
                current_epoch = progress['current']
                
                # Calculate speed
                current_time = time.time()
                if current_epoch > last_epoch:
                    time_diff = current_time - last_update_time
                    epochs_diff = current_epoch - last_epoch
                    if time_diff > 0:
                        epochs_per_sec = epochs_diff / time_diff
                        time_per_epoch = time_diff / epochs_diff
                    else:
                        epochs_per_sec = 0
                        time_per_epoch = 0
                    
                    last_update_time = current_time
                    last_epoch = current_epoch
                else:
                    epochs_per_sec = 0
                    time_per_epoch = progress.get('time_per_epoch', 0)
                
                # Calculate ETA
                remaining_epochs = total_epochs - current_epoch
                if epochs_per_sec > 0:
                    eta_seconds = remaining_epochs / epochs_per_sec
                elif time_per_epoch > 0:
                    eta_seconds = remaining_epochs * time_per_epoch
                else:
                    eta_seconds = 0
                
                # Calculate elapsed time
                elapsed_seconds = current_time - start_time
                
                # Print progress block (simple scrolling output for Colab compatibility)
                print(f"\n{Colors.OKCYAN}{'‚îÄ'*80}{Colors.ENDC}")
                print(f"{Colors.BOLD}Epoch: {Colors.OKGREEN}{current_epoch}/{total_epochs}{Colors.ENDC} {Colors.BOLD}({progress['percent']}%){Colors.ENDC}")
                print(f"{Colors.OKCYAN}{print_progress_bar(progress['percent'])}{Colors.ENDC}")
                
                # Metrics
                metrics_line = []
                if progress['t_loss'] is not None:
                    metrics_line.append(f"{Colors.BOLD}Loss:{Colors.ENDC} {Colors.WARNING}{progress['t_loss']:.4f}{Colors.ENDC}")
                if progress['i_acc'] is not None:
                    metrics_line.append(f"{Colors.BOLD}Intent Acc:{Colors.ENDC} {Colors.OKGREEN}{progress['i_acc']:.4f}{Colors.ENDC}")
                if progress['e_f1'] is not None:
                    metrics_line.append(f"{Colors.BOLD}Entity F1:{Colors.ENDC} {Colors.OKGREEN}{progress['e_f1']:.4f}{Colors.ENDC}")
                if progress['m_acc'] is not None:
                    metrics_line.append(f"{Colors.BOLD}Memory Acc:{Colors.ENDC} {Colors.OKGREEN}{progress['m_acc']:.4f}{Colors.ENDC}")
                
                if metrics_line:
                    print(f"  {' | '.join(metrics_line)}")
                
                # Speed and time info
                speed_line = []
                if epochs_per_sec > 0:
                    speed_line.append(f"{Colors.BOLD}T·ªëc ƒë·ªô:{Colors.ENDC} {Colors.OKCYAN}{epochs_per_sec:.3f} epochs/s{Colors.ENDC}")
                if time_per_epoch > 0:
                    speed_line.append(f"{Colors.BOLD}Th·ªùi gian/epoch:{Colors.ENDC} {Colors.OKCYAN}{format_time(time_per_epoch)}{Colors.ENDC}")
                speed_line.append(f"{Colors.BOLD}ƒê√£ tr√¥i qua:{Colors.ENDC} {Colors.OKCYAN}{format_time(elapsed_seconds)}{Colors.ENDC}")
                if eta_seconds > 0:
                    speed_line.append(f"{Colors.BOLD}ETA:{Colors.ENDC} {Colors.WARNING}{format_time(eta_seconds)}{Colors.ENDC}")
                
                if speed_line:
                    print(f"  {' | '.join(speed_line)}")
                print(f"{Colors.OKCYAN}{'‚îÄ'*80}{Colors.ENDC}", flush=True)
            else:
                # Print other important lines (warnings, errors, etc.)
                if any(keyword in line.lower() for keyword in ['warning', 'error', 'exception', 'traceback']):
                    print(f"\n{Colors.WARNING}{line}{Colors.ENDC}")
                elif any(keyword in line.lower() for keyword in ['success', 'complete', 'finished', 'done']):
                    print(f"\n{Colors.OKGREEN}{line}{Colors.ENDC}")
                elif line.strip() and not line.startswith('Epochs:'):
                    # Print other non-empty lines (but not progress lines)
                    if 'Processing' in line or 'Training' in line or 'Validating' in line:
                        print(f"\n{Colors.OKCYAN}{line}{Colors.ENDC}")
        
        # Wait for process to complete
        return_code = process.wait()
        
        print(f"\n{Colors.OKCYAN}{'='*80}{Colors.ENDC}\n")
        
        if return_code != 0:
            print_error(f"Training th·∫•t b·∫°i v·ªõi exit code: {return_code}")
            return False
        
        elapsed_time = time.time() - start_time
        hours = int(elapsed_time // 3600)
        minutes = int((elapsed_time % 3600) // 60)
        seconds = int(elapsed_time % 60)
        
        print_success(f"Training ho√†n t·∫•t! Th·ªùi gian: {hours}h {minutes}m {seconds}s")
        
        # Print final metrics if available
        if progress_data:
            print(f"\n{Colors.BOLD}üìä K·∫øt qu·∫£ cu·ªëi c√πng:{Colors.ENDC}")
            if progress_data['t_loss'] is not None:
                print(f"  {Colors.BOLD}Training Loss:{Colors.ENDC} {progress_data['t_loss']:.4f}")
            if progress_data['i_acc'] is not None:
                print(f"  {Colors.BOLD}Intent Accuracy:{Colors.ENDC} {progress_data['i_acc']:.4f}")
            if progress_data['e_f1'] is not None:
                print(f"  {Colors.BOLD}Entity F1 Score:{Colors.ENDC} {progress_data['e_f1']:.4f}")
            if progress_data['m_acc'] is not None:
                print(f"  {Colors.BOLD}Memory Accuracy:{Colors.ENDC} {progress_data['m_acc']:.4f}")
        
        return True
        
    except subprocess.CalledProcessError as e:
        print_error(f"L·ªói khi train: {e}")
        return False
    except KeyboardInterrupt:
        print_warning("\nTraining b·ªã d·ª´ng b·ªüi ng∆∞·ªùi d√πng")
        if 'process' in locals():
            process.terminate()
        return False
    except Exception as e:
        print_error(f"L·ªói kh√¥ng mong ƒë·ª£i: {e}")
        import traceback
        traceback.print_exc()
        return False

def get_latest_model():
    """Get the latest trained model"""
    models_dir = Path("models")
    if not models_dir.exists():
        return None
    
    # Find all .tar.gz files
    model_files = list(models_dir.glob("*.tar.gz"))
    if not model_files:
        return None
    
    # Sort by modification time
    model_files.sort(key=lambda x: x.stat().st_mtime, reverse=True)
    return model_files[0]

def download_model_to_local():
    """Download model to local machine (Colab specific)"""
    if not is_colab():
        print_warning("Kh√¥ng ph·∫£i Colab environment - b·ªè qua download")
        return
    
    print_header("T·∫¢I MODEL V·ªÄ M√ÅY LOCAL")
    
    latest_model = get_latest_model()
    if not latest_model:
        print_error("Kh√¥ng t√¨m th·∫•y model ƒë√£ train")
        return
    
    print_info(f"Model m·ªõi nh·∫•t: {latest_model.name}")
    print_info(f"K√≠ch th∆∞·ªõc: {latest_model.stat().st_size / (1024*1024):.2f} MB")
    
    try:
        from google.colab import files
        files.download(str(latest_model))
        print_success("ƒê√£ b·∫Øt ƒë·∫ßu t·∫£i model v·ªÅ m√°y local")
    except Exception as e:
        print_error(f"L·ªói khi t·∫£i model: {e}")
        print_info(f"B·∫°n c√≥ th·ªÉ t·∫£i th·ªß c√¥ng t·ª´: {latest_model}")

def main():
    """Main function"""
    print_header("RASA NLU TRAINING TR√äN GOOGLE COLAB")
    
    # Check environment
    if is_colab():
        print_success("ƒêang ch·∫°y tr√™n Google Colab")
        
        # Step 0: Cleanup and clone fresh repo (Colab only)
        print_header("CLEANUP V√Ä CLONE REPO M·ªöI")
        print_info("üîÑ ƒêang x√≥a repo c≈© v√† clone repo m·ªõi t·ª´ git...")
        
        # Get git URL and branch from environment or use defaults
        git_url = os.environ.get("CIESTA_GIT_URL", "https://github.com/HoangPhucDE/ciesta-assistant.git")
        git_branch = os.environ.get("CIESTA_GIT_BRANCH", "main")
        
        print_info(f"   Git URL: {git_url}")
        print_info(f"   Branch: {git_branch}")
        
        # Go to /content (Colab's default directory)
        content_dir = Path("/content")
        if content_dir.exists():
            os.chdir(content_dir)
            print_info(f"ƒê√£ chuy·ªÉn v√†o: {Path.cwd()}")
        
        # Cleanup and clone
        if cleanup_and_clone_repo(git_url=git_url, branch=git_branch, target_dir="ciesta-assistant"):
            print_success("‚úÖ ƒê√£ clone repo m·ªõi th√†nh c√¥ng")
            # Now we're in the cloned directory
            project_root = Path.cwd()
        else:
            print_warning("‚ö†Ô∏è Kh√¥ng th·ªÉ clone repo m·ªõi, s·∫Ω t√¨m project root hi·ªán c√≥...")
            project_root = find_project_root()
            if project_root:
                os.chdir(project_root)
                print_info(f"ƒê√£ chuy·ªÉn v√†o project root: {Path.cwd()}")
            else:
                print_error("Kh√¥ng t√¨m th·∫•y project root")
                return False
    else:
        print_warning("Kh√¥ng ph·∫£i Colab - script v·∫´n ho·∫°t ƒë·ªông nh∆∞ng m·ªôt s·ªë t√≠nh nƒÉng c√≥ th·ªÉ b·ªã gi·ªõi h·∫°n")
        
        # Find and change to project root first
        project_root = find_project_root()
        if project_root:
            original_dir = Path.cwd()
            
            # Avoid nested directories
            if "ciesta-assistant" in str(project_root) and "ciesta-assistant" in str(original_dir):
                # Check if we're going into a nested directory
                parts_original = str(original_dir).split("ciesta-assistant")
                parts_project = str(project_root).split("ciesta-assistant")
                if len(parts_project) > len(parts_original):
                    # We're going deeper, use the outer one
                    outer_path = Path(str(original_dir).split("ciesta-assistant")[0]) / "ciesta-assistant"
                    if outer_path.exists() and (outer_path / "requirements.txt").exists():
                        project_root = outer_path
                        print_warning(f"Ph√°t hi·ªán nested directory, s·ª≠ d·ª•ng: {project_root}")
            
            os.chdir(project_root)
            print_info(f"ƒê√£ chuy·ªÉn t·ª´ {original_dir} sang {Path.cwd()}")
            
            # Verify we're in the right place
            if not (Path.cwd() / "requirements.txt").exists() and not (Path.cwd() / "requirements-colab.txt").exists():
                print_error("Kh√¥ng t√¨m th·∫•y requirements file trong project root")
                return False
        else:
            print_warning("Kh√¥ng t√¨m th·∫•y project root, ti·∫øp t·ª•c v·ªõi th∆∞ m·ª•c hi·ªán t·∫°i")
            print_info(f"Th∆∞ m·ª•c hi·ªán t·∫°i: {Path.cwd()}")
            print_info("Vui l√≤ng ƒë·∫£m b·∫£o b·∫°n ƒë√£ clone repo v√† chuy·ªÉn v√†o th∆∞ m·ª•c ciesta-assistant")
    
    # Verify we're in the right place
    if not (Path.cwd() / "requirements.txt").exists() and not (Path.cwd() / "requirements-colab.txt").exists():
        print_error("Kh√¥ng t√¨m th·∫•y requirements file trong project root")
        print_info(f"Th∆∞ m·ª•c hi·ªán t·∫°i: {Path.cwd()}")
        return False
    
    # Step 1: Install dependencies
    if not install_dependencies():
        print_error("C√†i ƒë·∫∑t dependencies th·∫•t b·∫°i")
        return False
    
    # Step 2: Setup project structure
    if not setup_project_structure():
        print_error("Thi·∫øt l·∫≠p c·∫•u tr√∫c project th·∫•t b·∫°i")
        return False
    
    # Step 3: Download model
    if not download_phobert_model():
        print_error("T·∫£i model th·∫•t b·∫°i")
        return False
    
    # Step 4: Create symlink
    if not create_symlink():
        print_error("T·∫°o symlink th·∫•t b·∫°i")
        return False
    
    # Step 5: Setup custom components
    if not setup_custom_components():
        print_error("Thi·∫øt l·∫≠p custom components th·∫•t b·∫°i")
        return False
    
    # Step 5.5: C·∫≠p nh·∫≠t config ƒë·ªÉ d√πng model online
    print_header("C·∫¨P NH·∫¨T CONFIG")
    current_dir = Path.cwd()
    
    # T√¨m file config (c√≥ th·ªÉ ·ªü root ho·∫∑c trong config/rasa/)
    config_paths = [
        current_dir / "config.yml",
        current_dir / "config/rasa/config.yml",
    ]
    
    config_file = None
    config_path_used = None
    
    for path in config_paths:
        if path.exists():
            config_file = str(path)
            config_path_used = path
            print_info(f"T√¨m th·∫•y config t·∫°i: {path}")
            break
    
    if not config_file:
        print_error("Kh√¥ng t√¨m th·∫•y config.yml")
        return False
    
    # N·∫øu config ·ªü trong config/rasa/, copy v√†o root ƒë·ªÉ Rasa t√¨m th·∫•y
    root_config = current_dir / "config.yml"
    rasa_config = current_dir / "config/rasa/config.yml"
    
    if config_path_used == rasa_config:
        print_info(f"Copy config t·ª´ {rasa_config} -> {root_config}")
        
        # X√≥a file c≈© n·∫øu t·ªìn t·∫°i
        root_config_str = str(root_config)
        if os.path.lexists(root_config_str):
            try:
                if os.path.islink(root_config_str):
                    os.unlink(root_config_str)
                else:
                    os.remove(root_config_str)
            except Exception:
                pass
        
        # Copy file
        try:
            shutil.copyfile(str(rasa_config), root_config_str)
            if os.path.exists(root_config_str) and os.path.isfile(root_config_str):
                print_success("ƒê√£ copy config.yml v√†o root")
                config_file = "config.yml"
        except Exception as e:
            print_error(f"Kh√¥ng th·ªÉ copy file: {e}")
            return False
    
    # Copy c√°c file config kh√°c v√†o root
    rasa_config_files = ["domain.yml", "endpoints.yml", "credentials.yml"]
    for filename in rasa_config_files:
        rasa_path = current_dir / "config/rasa" / filename
        root_path = current_dir / filename
        
        if rasa_path.exists():
            root_path_str = str(root_path)
            if os.path.lexists(root_path_str):
                try:
                    if os.path.islink(root_path_str):
                        os.unlink(root_path_str)
                    else:
                        os.remove(root_path_str)
                except Exception:
                    pass
            
            try:
                shutil.copyfile(str(rasa_path), root_path_str)
                if os.path.exists(root_path_str) and os.path.isfile(root_path_str):
                    print_success(f"ƒê√£ copy {filename} v√†o root")
            except Exception as e:
                print_warning(f"Kh√¥ng th·ªÉ copy {filename}: {e}")
    
    # ƒê·ªçc v√† c·∫≠p nh·∫≠t config (ƒë·∫£m b·∫£o d√πng file ·ªü root)
    config_to_update = current_dir / "config.yml"
    
    if not config_to_update.exists():
        print_error("config.yml kh√¥ng t·ªìn t·∫°i ·ªü root!")
        return False
    
    print_info(f"ƒêang c·∫≠p nh·∫≠t: {config_to_update}")
    
    # ƒê·ªçc config
    with open(config_to_update, "r", encoding="utf-8") as f:
        config = f.read()
    
    # C·∫≠p nh·∫≠t config ƒë·ªÉ d√πng model online
    config = re.sub(r'model_name:\s*"models/phobert-large"', 'model_name: "vinai/phobert-large"', config)
    config = re.sub(r'cache_dir:\s*null', 'cache_dir: "models_hub/phobert_cache"', config)
    
    # Ghi l·∫°i config v√†o root
    with open(config_to_update, "w", encoding="utf-8") as f:
        f.write(config)
    
    # C≈©ng c·∫≠p nh·∫≠t file g·ªëc trong config/rasa/ ƒë·ªÉ ƒë·ªìng b·ªô
    if rasa_config.exists():
        with open(rasa_config, "w", encoding="utf-8") as f:
            f.write(config)
        print_success("ƒê√£ c·∫≠p nh·∫≠t c·∫£ file g·ªëc trong config/rasa/")
    
    print_success("ƒê√£ c·∫≠p nh·∫≠t config ƒë·ªÉ d√πng model online")
    
    # Step 6: Verify config
    if not verify_config():
        print_warning("Config c√≥ th·ªÉ ch∆∞a ƒë√∫ng - vui l√≤ng ki·ªÉm tra")
    
    # Step 6.5: Entity alignments
    # L∆∞u √Ω: Entity alignments n√™n ƒë∆∞·ª£c fix tr∆∞·ªõc b·∫±ng script sync_location_names.py
    # Script n√†y ch·ªâ ph·ª•c v·ª• training, kh√¥ng fix entities
    # Xem docs/README_SYNC_LOCATIONS.md ƒë·ªÉ bi·∫øt th√™m chi ti·∫øt
    print_info("üí° L∆∞u √Ω: N·∫øu c√≥ entity alignment warnings, ch·∫°y sync_location_names.py tr∆∞·ªõc khi train")
    print_info("   Xem: scripts/training/sync_location_names.py ho·∫∑c docs/README_SYNC_LOCATIONS.md")
    
    # Step 7: Optimize config for GPU
    print_header("T·ªêI ∆ØU H√ìA CONFIG CHO GPU")
    gpu_info = get_gpu_info()
    if gpu_info['available']:
        config_file_path = Path("config.yml")
        if not config_file_path.exists():
            config_file_path = Path("config/rasa/config.yml")
        optimize_config_for_gpu(config_file_path, gpu_info)
        
        # Ultra optimization cho GPU l·ªõn (T4/V100/A100)
        if gpu_info.get('memory_gb', 0) >= 14.5:
            ultra_optimize_for_gpu(config_file_path)
    
    # Step 7.5: Verify config
    verify_config()
    
    # Step 8: Train NLU
    if not train_nlu():
        print_error("Training th·∫•t b·∫°i")
        return False
    
    # Step 9: Download model
    download_model_to_local()
    
    print_header("HO√ÄN T·∫§T!")
    print_success("Training ƒë√£ ho√†n t·∫•t th√†nh c√¥ng!")
    
    latest_model = get_latest_model()
    if latest_model:
        print_info(f"Model ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i: {latest_model}")
    
    return True

if __name__ == "__main__":
    try:
        success = main()
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        print_warning("\nScript b·ªã d·ª´ng b·ªüi ng∆∞·ªùi d√πng")
        sys.exit(1)
    except Exception as e:
        print_error(f"L·ªói kh√¥ng mong ƒë·ª£i: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)