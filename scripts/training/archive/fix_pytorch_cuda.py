#!/usr/bin/env python3
"""
Script Python ƒë·ªÉ fix v·∫•n ƒë·ªÅ PyTorch kh√¥ng nh·∫≠n di·ªán GPU
Ch·∫°y script n√†y n·∫øu PyTorch kh√¥ng detect ƒë∆∞·ª£c GPU m·∫∑c d√π ƒë√£ c√≥ CUDA
"""

import subprocess
import sys

def run_command(cmd, check=True):
    """Ch·∫°y command v√† return output"""
    try:
        result = subprocess.run(
            cmd, shell=True, capture_output=True, text=True, check=check
        )
        return result.stdout.strip(), result.returncode
    except subprocess.CalledProcessError as e:
        return e.stdout.strip(), e.returncode

def check_nvidia_smi():
    """Ki·ªÉm tra nvidia-smi - t√¨m ·ªü nhi·ªÅu v·ªã tr√≠"""
    # Th·ª≠ c√°c l·ªánh kh√°c nhau
    commands = [
        "nvidia-smi --query-gpu=name,driver_version,cuda_version --format=csv,noheader",
        "/usr/bin/nvidia-smi --query-gpu=name,driver_version,cuda_version --format=csv,noheader",
        "/usr/local/bin/nvidia-smi --query-gpu=name,driver_version,cuda_version --format=csv,noheader",
        "which nvidia-smi && nvidia-smi --query-gpu=name,driver_version,cuda_version --format=csv,noheader",
    ]
    
    for cmd in commands:
        output, code = run_command(cmd, check=False)
        if code == 0 and output:
            return output
    
    return None

def main():
    print("üîß FIX PYTORCH CUDA - C√†i ƒë·∫∑t PyTorch v·ªõi CUDA support")
    print("=" * 60)
    print()
    
    # Ki·ªÉm tra nvidia-smi
    nvidia_info = check_nvidia_smi()
    if nvidia_info:
        print("‚úÖ T√¨m th·∫•y GPU qua nvidia-smi:")
        for line in nvidia_info.split('\n'):
            if line.strip():
                parts = line.split(', ')
                if len(parts) >= 3:
                    print(f"   GPU: {parts[0].strip()}")
                    print(f"   Driver: {parts[1].strip()}")
                    print(f"   CUDA (System): {parts[2].strip()}")
        print()
    else:
        print("‚ö†Ô∏è  Kh√¥ng t√¨m th·∫•y nvidia-smi trong PATH")
        print("   (Nh∆∞ng b·∫°n c√≥ th·ªÉ v·∫´n c√≥ GPU)")
        print()
        
        # H·ªèi user x√°c nh·∫≠n
        try:
            confirm = input("B·∫°n c√≥ GPU NVIDIA v√† mu·ªën ti·∫øp t·ª•c c√†i ƒë·∫∑t PyTorch v·ªõi CUDA? (y/n): ").strip().lower()
            if confirm != 'y' and confirm != 'yes':
                print("‚ùå ƒê√£ h·ªßy")
                sys.exit(0)
        except KeyboardInterrupt:
            print("\n‚ùå ƒê√£ h·ªßy")
            sys.exit(0)
    
    # Ki·ªÉm tra PyTorch hi·ªán t·∫°i
    try:
        import torch
        print(f"üì¶ PyTorch hi·ªán t·∫°i: {torch.__version__}")
        print(f"   CUDA available: {torch.cuda.is_available()}")
        if torch.cuda.is_available():
            print(f"   GPU: {torch.cuda.get_device_name(0)}")
            print()
            print("‚úÖ GPU ƒë√£ ƒë∆∞·ª£c nh·∫≠n di·ªán! Kh√¥ng c·∫ßn fix.")
            sys.exit(0)
    except ImportError:
        print("‚ö†Ô∏è  PyTorch ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t")
    except Exception as e:
        print(f"‚ö†Ô∏è  L·ªói khi ki·ªÉm tra PyTorch: {e}")
    print()
    
    # H·ªèi user ch·ªçn CUDA version
    print("Ch·ªçn CUDA version ƒë·ªÉ c√†i ƒë·∫∑t PyTorch:")
    print("1. CUDA 12.1 (khuy·∫øn ngh·ªã - t∆∞∆°ng th√≠ch v·ªõi CUDA 12.x v√† 13.0)")
    print("2. CUDA 12.4 (t∆∞∆°ng th√≠ch v·ªõi CUDA 12.x v√† 13.0)")
    print("3. CUDA 11.8 (cho h·ªá th·ªëng c≈©)")
    print("4. CPU only (kh√¥ng c√≥ GPU)")
    
    try:
        choice = input("Ch·ªçn (1/2/3/4, m·∫∑c ƒë·ªãnh: 1): ").strip() or "1"
    except KeyboardInterrupt:
        print("\n‚ùå ƒê√£ h·ªßy")
        sys.exit(1)
    
    cuda_versions = {
        "1": ("cu121", "https://download.pytorch.org/whl/cu121", True),
        "2": ("cu124", "https://download.pytorch.org/whl/cu124", True),
        "3": ("cu118", "https://download.pytorch.org/whl/cu118", True),
        "4": (None, None, False),  # CPU only
    }
    
    if choice not in cuda_versions:
        print("‚ùå L·ª±a ch·ªçn kh√¥ng h·ª£p l·ªá")
        sys.exit(1)
    
    cuda_version, index_url, use_cuda = cuda_versions[choice]
    
    if not use_cuda:
        # CPU only
        print()
        print("üì¶ ƒêang g·ª° PyTorch c≈©...")
        run_command("pip uninstall -y torch torchvision torchaudio", check=False)
        
        print()
        print("üì¶ ƒêang c√†i ƒë·∫∑t PyTorch (CPU only)...")
        output, code = run_command("pip install torch torchvision torchaudio", check=False)
        
        if code != 0:
            print("‚ùå L·ªói khi c√†i ƒë·∫∑t PyTorch:")
            print(output)
            sys.exit(1)
        
        print()
        print("‚úÖ ƒê√£ c√†i ƒë·∫∑t PyTorch (CPU only)")
        print("‚ö†Ô∏è  Training s·∫Ω ch·∫≠m h∆°n nhi·ªÅu so v·ªõi GPU")
        sys.exit(0)
    
    print()
    print("üì¶ ƒêang g·ª° PyTorch c≈©...")
    output, _ = run_command("pip uninstall -y torch torchvision torchaudio", check=False)
    if output:
        print("   (ƒê√£ g·ª° c√°c package c≈©)")
    
    print()
    print(f"üì¶ ƒêang c√†i ƒë·∫∑t PyTorch v·ªõi CUDA {cuda_version}...")
    print("   (Qu√° tr√¨nh n√†y c√≥ th·ªÉ m·∫•t 2-5 ph√∫t, vui l√≤ng ƒë·ª£i...)")
    print(f"   URL: {index_url}")
    cmd = f"pip install torch torchvision torchaudio --index-url {index_url}"
    output, code = run_command(cmd, check=False)
    
    if code != 0:
        print("‚ùå L·ªói khi c√†i ƒë·∫∑t PyTorch:")
        print(output)
        sys.exit(1)
    
    print()
    print("üîç Ki·ªÉm tra c√†i ƒë·∫∑t...")
    try:
        import torch
        print(f"   PyTorch version: {torch.__version__}")
        print(f"   CUDA available: {torch.cuda.is_available()}")
        if torch.cuda.is_available():
            print(f"   CUDA version: {torch.version.cuda}")
            print(f"   GPU: {torch.cuda.get_device_name(0)}")
            print()
            print("‚úÖ Th√†nh c√¥ng! GPU ƒë√£ ƒë∆∞·ª£c PyTorch nh·∫≠n di·ªán")
            print()
            print("üöÄ B√¢y gi·ªù b·∫°n c√≥ th·ªÉ train v·ªõi GPU:")
            print("   rasa train nlu")
        else:
            print()
            print("‚ùå V·∫´n ch∆∞a nh·∫≠n di·ªán ƒë∆∞·ª£c GPU")
            print()
            print("üí° Th·ª≠ c√°c gi·∫£i ph√°p sau:")
            print("   1. Restart terminal/IDE")
            print("   2. Ki·ªÉm tra CUDA toolkit ƒë√£ ƒë∆∞·ª£c c√†i ƒë·∫∑t:")
            print("      nvcc --version")
            print("   3. Ki·ªÉm tra PATH c√≥ ch·ª©a CUDA:")
            print("      echo $PATH | grep cuda")
            print("   4. C√†i ƒë·∫∑t CUDA toolkit n·∫øu ch∆∞a c√≥:")
            print("      https://developer.nvidia.com/cuda-downloads")
    except ImportError:
        print("‚ùå Kh√¥ng th·ªÉ import torch sau khi c√†i ƒë·∫∑t")
        sys.exit(1)
    except Exception as e:
        print(f"‚ùå L·ªói khi ki·ªÉm tra: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()

