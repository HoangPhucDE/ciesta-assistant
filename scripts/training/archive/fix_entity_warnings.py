#!/usr/bin/env python3
"""
Script Ä‘Æ¡n giáº£n Ä‘á»ƒ fix entity alignment warnings trong training data

CÃ¡ch sá»­ dá»¥ng:
    python scripts/training/fix_entity_warnings.py

Script nÃ y sáº½:
1. Sá»­ dá»¥ng Rasa Ä‘á»ƒ validate training data
2. XÃ¡c Ä‘á»‹nh cÃ¡c examples cÃ³ entity alignment issues
3. Fix tá»± Ä‘á»™ng cÃ¡c issues Ä‘Æ¡n giáº£n
4. BÃ¡o cÃ¡o cÃ¡c issues cáº§n fix thá»§ cÃ´ng
"""

import sys
from pathlib import Path

try:
    from rasa.shared.nlu.training_data.formats.rasa_yaml import RasaYAMLReader
    from rasa.nlu.tokenizers.whitespace_tokenizer import WhitespaceTokenizer
    RASA_AVAILABLE = True
except ImportError:
    print("âš ï¸ Rasa khÃ´ng Ä‘Æ°á»£c cÃ i Ä‘áº·t. Vui lÃ²ng cÃ i Ä‘áº·t Rasa trÆ°á»›c.")
    print("   pip install rasa")
    RASA_AVAILABLE = False
    sys.exit(1)


def validate_and_fix_entities(nlu_file: Path):
    """Validate vÃ  fix entity alignments trong file NLU"""
    print(f"ğŸ“– Äá»c file: {nlu_file}")
    
    # Load training data
    reader = RasaYAMLReader()
    training_data = reader.read(nlu_file)
    
    print(f"ğŸ” Äang kiá»ƒm tra {len(training_data.training_examples)} examples...")
    
    # Tokenizer
    tokenizer = WhitespaceTokenizer()
    
    fixed_count = 0
    issues_found = []
    
    for example in training_data.training_examples:
        text = example.get("text")
        entities = example.get("entities", [])
        
        if not entities:
            continue
        
        # Tokenize text
        message_data = {"text": text}
        tokens = tokenizer.tokenize(message_data, attribute="text")
        
        if not tokens:
            continue
        
        # Kiá»ƒm tra tá»«ng entity
        for entity in entities:
            entity_start = entity["start"]
            entity_end = entity["end"]
            entity_value = entity["value"]
            
            # TÃ¬m tokens náº±m trong entity range
            entity_tokens = [
                t for t in tokens
                if t.start < entity_end and t.end > entity_start
            ]
            
            if not entity_tokens:
                # Entity khÃ´ng overlap vá»›i tokens - cáº§n fix
                issues_found.append({
                    "text": text,
                    "entity": entity_value,
                    "issue": "Entity khÃ´ng overlap vá»›i tokens",
                    "entity_start": entity_start,
                    "entity_end": entity_end
                })
                continue
            
            # Kiá»ƒm tra xem entity cÃ³ báº¯t Ä‘áº§u/ káº¿t thÃºc á»Ÿ token boundaries khÃ´ng
            aligned_start = min(t.start for t in entity_tokens)
            aligned_end = max(t.end for t in entity_tokens)
            
            if aligned_start != entity_start or aligned_end != entity_end:
                # Entity khÃ´ng align vá»›i token boundaries - fix
                entity["start"] = aligned_start
                entity["end"] = aligned_end
                entity["value"] = text[aligned_start:aligned_end]
                fixed_count += 1
    
    print(f"\nğŸ“Š Káº¿t quáº£:")
    print(f"   - ÄÃ£ fix: {fixed_count} entities")
    print(f"   - Issues cáº§n fix thá»§ cÃ´ng: {len(issues_found)}")
    
    if issues_found:
        print(f"\nâš ï¸ CÃ¡c issues cáº§n fix thá»§ cÃ´ng:")
        for i, issue in enumerate(issues_found[:10], 1):  # Chá»‰ hiá»ƒn thá»‹ 10 Ä‘áº§u tiÃªn
            print(f"   {i}. Text: {issue['text'][:50]}...")
            print(f"      Entity: {issue['entity']}")
            print(f"      Issue: {issue['issue']}")
    
    # Save láº¡i file
    if fixed_count > 0:
        backup_file = nlu_file.with_suffix('.yml.bak')
        if not backup_file.exists():
            import shutil
            shutil.copy2(nlu_file, backup_file)
            print(f"\nğŸ’¾ Backup file gá»‘c: {backup_file}")
        
        # Note: Rasa khÃ´ng cÃ³ writer trá»±c tiáº¿p, cáº§n dÃ¹ng cÃ¡ch khÃ¡c
        print(f"\nğŸ’¡ ÄÃ£ fix {fixed_count} entities trong memory")
        print(f"ğŸ’¡ Äá»ƒ lÆ°u láº¡i, cáº§n sá»­ dá»¥ng Rasa's training data writer")
        print(f"ğŸ’¡ Hoáº·c cháº¡y láº¡i training Ä‘á»ƒ Rasa tá»± Ä‘á»™ng fix")
    
    return fixed_count, issues_found


def main():
    """Main function"""
    nlu_file = Path("data/nlu.yml")
    
    if not nlu_file.exists():
        print(f"âŒ File khÃ´ng tá»“n táº¡i: {nlu_file}")
        sys.exit(1)
    
    validate_and_fix_entities(nlu_file)


if __name__ == '__main__':
    main()

